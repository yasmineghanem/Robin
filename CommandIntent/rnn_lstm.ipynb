{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1 : RNN (LSTM) \n",
    "can handle sequential data (sentences) effectively\n",
    "1. Embedding layer\n",
    "2. LSTM layer (sequence processing)\n",
    "3. Two dense layers for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import utils\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install keras2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_data(file_path):\n",
    "    '''\n",
    "    This function loads the data from the file_path\n",
    "\n",
    "    Given the path of the dataset this function reads and returns the intents and the corpus of the dataset\n",
    "\n",
    "    Args:\n",
    "        - file_path (str) : path of the dataset\n",
    "\n",
    "    Returns:\n",
    "        - unique_intents (list[str]) : list of unique intents in the dataset\n",
    "        - corpus (list[str]) : list of all the sentences in the dataset\n",
    "        - corpus_intents (list[str]) : list of intents for each sentence in the dataset\n",
    "        - responses (list[str]) : list of responses for each intent in the dataset\n",
    "    '''\n",
    "    unique_intents = []\n",
    "    corpus = []\n",
    "    corpus_intents = []\n",
    "    # responses = []\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "        print(dataset.keys())\n",
    "        # intents = dataset['intents']\n",
    "\n",
    "        for intent, values in dataset.items():\n",
    "            print(intent.lower())\n",
    "            print(len(values))\n",
    "            if intent not in unique_intents:\n",
    "                unique_intents.append(intent)\n",
    "            for sentence in values:\n",
    "                corpus.append(utils.clean(sentence))\n",
    "                corpus_intents.append(intent)\n",
    "\n",
    "    return unique_intents, corpus, corpus_intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Variable Declaration', 'Constant Declaration', 'Function Declaration', 'Class Declaration', 'Assignment Operation', 'Conditional Statement', 'For Loop', 'While Loop', 'Array Operation', 'Bitwise Operation', 'Mathematical Operation', 'Membership Operation', 'Casting', 'Input', 'Output', 'Assertion', 'Libraries', 'File System', 'IDE Operation', 'Comment', 'Activate Mouse', 'Activate Interactive', 'Interactive Commands', 'Git Operation', 'Exit Block', 'Mouse Click'])\n",
      "variable declaration\n",
      "239\n",
      "constant declaration\n",
      "200\n",
      "function declaration\n",
      "90\n",
      "class declaration\n",
      "30\n",
      "assignment operation\n",
      "80\n",
      "conditional statement\n",
      "160\n",
      "for loop\n",
      "120\n",
      "while loop\n",
      "60\n",
      "array operation\n",
      "110\n",
      "bitwise operation\n",
      "80\n",
      "mathematical operation\n",
      "370\n",
      "membership operation\n",
      "160\n",
      "casting\n",
      "60\n",
      "input\n",
      "50\n",
      "output\n",
      "120\n",
      "assertion\n",
      "40\n",
      "libraries\n",
      "40\n",
      "file system\n",
      "150\n",
      "ide operation\n",
      "300\n",
      "comment\n",
      "50\n",
      "activate mouse\n",
      "40\n",
      "activate interactive\n",
      "30\n",
      "interactive commands\n",
      "220\n",
      "git operation\n",
      "80\n",
      "exit block\n",
      "26\n",
      "mouse click\n",
      "11\n",
      "Number of unique intents: 26\n",
      "Number of examples: 2916\n",
      "Number of examples: 2916\n",
      "Unique intents: ['Variable Declaration', 'Constant Declaration', 'Function Declaration', 'Class Declaration', 'Assignment Operation', 'Conditional Statement', 'For Loop', 'While Loop', 'Array Operation', 'Bitwise Operation', 'Mathematical Operation', 'Membership Operation', 'Casting', 'Input', 'Output', 'Assertion', 'Libraries', 'File System', 'IDE Operation', 'Comment', 'Activate Mouse', 'Activate Interactive', 'Interactive Commands', 'Git Operation', 'Exit Block', 'Mouse Click']\n",
      "Samples: ['make start time as double and initialize', 'declare min value as integer and value', 'define settings as boolean and value false', 'define y as integer and assign to', 'initialize k as string and initialize it with Code Review']\n",
      "Training Sample:  ('make start time as double and initialize', 'Variable Declaration')\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './intent_detection_dataset/final_intents_dataset.json'\n",
    "unique_intents, corpus, corpus_intents = load_data(dataset_path)\n",
    "\n",
    "# print shapes and sizes of the dataset\n",
    "print('Number of unique intents:', len(unique_intents))\n",
    "# print('Number of responses:', len(responses))\n",
    "print('Number of examples:', len(corpus))\n",
    "print('Number of examples:', len(corpus_intents))\n",
    "\n",
    "# print samples of the dataset\n",
    "print('Unique intents:', unique_intents)\n",
    "# print('Responses:', responses)\n",
    "print('Samples:', corpus[:5])\n",
    "\n",
    "data = list(zip(corpus, corpus_intents))\n",
    "\n",
    "print(\"Training Sample: \", data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Tokenizing and Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'<unk>': 1, 'the': 2, 'and': 3, 'to': 4, 'a': 5, 'is': 6, 'it': 7, 'in': 8, 'name': 9, 'new': 10, 'value': 11, 'variable': 12, 'user': 13, 'with': 14, 'of': 15, 'constant': 16, 'list': 17, 'as': 18, 'assign': 19, 'set': 20, 'equal': 21, 'file': 22, 'whether': 23, 'if': 24, 'for': 25, 'check': 26, 'message': 27, 'than': 28, 'initialize': 29, 'declare': 30, 'make': 31, 'loop': 32, 'from': 33, 'create': 34, 'not': 35, 'or': 36, 'date': 37, 'get': 38, 'array': 39, 'type': 40, 'data': 41, 'code': 42, 'are': 43, 'all': 44, 'line': 45, 'define': 46, 'while': 47, 'bitwise': 48, 'comment': 49, 'under': 50, 'product': 51, 'number': 52, 'step': 53, 'config': 54, 'range': 55, 'store': 56, 'write': 57, 'me': 58, 'allocate': 59, 'power': 60, 'output': 61, 'time': 62, 'that': 63, 'parameters': 64, 'last': 65, 'less': 66, 'using': 67, 'errors': 68, 'same': 69, 'index': 70, 'show': 71, 'string': 72, 'end': 73, 'has': 74, 'amount': 75, 'labelled': 76, 'algorithm': 77, 'save': 78, 'total': 79, 'greater': 80, 'terminal': 81, 'go': 82, 'mode': 83, 'id': 84, 'please': 85, 'called': 86, 'display': 87, 'settings': 88, 'mouse': 89, 'titled': 90, 'email': 91, 'project': 92, 'item': 93, 'order': 94, 'files': 95, 'named': 96, 'map': 97, 'add': 98, 'changes': 99, 'start': 100, 'identified': 101, 'address': 102, 'put': 103, 'integer': 104, 'rate': 105, 'float': 106, 'on': 107, 'raise': 108, 'selected': 109, 'folders': 110, 'fetch': 111, 'location': 112, 'equals': 113, 'multiplied': 114, 'char': 115, 'place': 116, 'path': 117, 'this': 118, 'boolean': 119, 'count': 120, 'result': 121, 'iteration': 122, 'dictionary': 123, 'contact': 124, 'class': 125, 'change': 126, 'int': 127, 'i': 128, 'retrieve': 129, 'root': 130, 'commit': 131, 'directories': 132, 'return': 133, 'returns': 134, 'operation': 135, 'enter': 136, 'interactive': 137, 'double': 138, 'element': 139, 'max': 140, 'out': 141, 'by': 142, 'character': 143, 'report': 144, 'shift': 145, 'key': 146, 'more': 147, 'iterate': 148, 'cube': 149, 'tax': 150, 'j': 151, 'average': 152, 'procedure': 153, 'min': 154, 'feature': 155, 'preferences': 156, 'system': 157, 'score': 158, 'zip': 159, 'insert': 160, 'copy': 161, 'delete': 162, 'account': 163, 'balance': 164, 'call': 165, 'temp': 166, 'supplier': 167, 'learning': 168, 'region': 169, 'functions': 170, 'bool': 171, 'flags': 172, 'pos': 173, 'its': 174, 'app': 175, 'subroutine': 176, 'colleague': 177, 'classes': 178, 'revenue': 179, 'reorder': 180, 'point': 181, 'queue': 182, 'city': 183, 'approved': 184, 'exit': 185, 'k': 186, 'employee': 187, 'record': 188, 'updated': 189, 'an': 190, 'find': 191, 'added': 192, 'divided': 193, 'square': 194, 'print': 195, 'switch': 196, 'true': 197, 'deleted': 198, 'counter': 199, 'expiry': 200, 'description': 201, 'collection': 202, 'condition': 203, 'include': 204, 'exponent': 205, 'ask': 206, 'library': 207, 'directory': 208, 'folder': 209, 'action': 210, 'review': 211, 'info': 212, 'expense': 213, 'enabled': 214, 'environment': 215, 'discount': 216, 'category': 217, 'position': 218, 'access': 219, 'empty': 220, 'default': 221, 'reverse': 222, 'use': 223, 'jump': 224, 'highlight': 225, 'logged': 226, 'visible': 227, 'current': 228, 'options': 229, 'e': 230, 'budget': 231, 'allocation': 232, 'routine': 233, 'office': 234, 'building': 235, 'right': 236, 'notes': 237, 'style': 238, 'methods': 239, 'country': 240, 'buffer': 241, 'xor': 242, 'left': 243, 'divide': 244, 'false': 245, 'development': 246, 'transaction': 247, 'database': 248, 'function': 249, 'mentor': 250, 'main': 251, 'evaluate': 252, 'determine': 253, 'read': 254, 'age': 255, 'verified': 256, 'creation': 257, 'status': 258, 'alternate': 259, 'input': 260, 'sum': 261, 'debit': 262, 'gender': 263, 'due': 264, 'programming': 265, 'customer': 266, 'properties': 267, 'method': 268, 'guardian': 269, 'street': 270, 'coordinates': 271, 'update': 272, 'delivery': 273, 'generate': 274, 'html': 275, 'plus': 276, 'division': 277, 'calculate': 278, 'solve': 279, 'subtraction': 280, 'require': 281, 'presentation': 282, 'pptx': 283, 'docx': 284, 'move': 285, 'technical': 286, 'models': 287, 'completed': 288, 'elapsed': 289, 'active': 290, 'stock': 291, 'quantity': 292, 'geo': 293, 'push': 294, 'identify': 295, 'tree': 296, 'multiplication': 297, 'text': 298, 'cast': 299, 'txt': 300, 'log': 301, 'open': 302, 'price': 303, 'gross': 304, 'income': 305, 'software': 306, 'inventory': 307, 'level': 308, 'language': 309, 'clustering': 310, 'algorithms': 311, 'net': 312, 'profit': 313, 'emergency': 314, 'subtract': 315, 'login': 316, 'addition': 317, 'work': 318, 'remainder': 319, 'transform': 320, 'validate': 321, 'mp': 322, 'cancel': 323, 'schedule': 324, 'credit': 325, 'limit': 326, 'partner': 327, 'secondary': 328, 'role': 329, 'frame': 330, 'duplicate': 331, 'script': 332, 'py': 333, 'json': 334, 'db': 335, 'choose': 336, 'mark': 337, 'cut': 338, 'stage': 339, 'click': 340, 'primary': 341, 'sibling': 342, 'form': 343, 'records': 344, 'discard': 345, 'remove': 346, 'sort': 347, 'clear': 348, 'perform': 349, 'css': 350, 'convert': 351, 'provide': 352, 'imports': 353, 'csv': 354, 'rename': 355, 'logfile': 356, 'pdf': 357, 'archive': 358, 'image': 359, 'jpg': 360, 'pick': 361, 'entire': 362, 'restore': 363, 'previous': 364, 'what': 365, 'just': 366, 'did': 367, 'tracking': 368, 'tracker': 369, 'mining': 370, 'network': 371, 'management': 372, 'support': 373, 'interface': 374, 'session': 375, 'singular': 376, 'items': 377, 'size': 378, 'apply': 379, 'multiply': 380, 'modulus': 381, 'navigate': 382, 'select': 383, 'revert': 384, 'redo': 385, 'disable': 386, 'pull': 387, 'stamp': 388, 'whose': 389, 'cascading': 390, 'sheets': 391, 'names': 392, 'structures': 393, 'having': 394, 'void': 395, 'including': 396, 'profile': 397, 'details': 398, 'carry': 399, 'compute': 400, 'confirm': 401, 'import': 402, 'diagram': 403, 'svg': 404, 'video': 405, 'repeat': 406, 'activte': 407, 'leave': 408, 'documentation': 409, 'regression': 410, 'functional': 411, 'hypertext': 412, 'markup': 413, 'architecture': 414, 'design': 415, 'qr': 416, 'lu': 417, 'cholesky': 418, 'accepts': 419, 'needs': 420, 'test': 421, 'cookies': 422, 'table': 423, 'spreadsheet': 424, 'xlsx': 425, 'summary': 426, 'videos': 427, 'kill': 428, 'undo': 429, 'enable': 430, 'deactivate': 431, 'engineering': 432, 'security': 433, 'version': 434, 'science': 435, 'neural': 436, 'networks': 437, 'javascript': 438, 'framework': 439, 'statistical': 440, 'back': 441, 'hello': 442, 'world': 443, 'deep': 444, 'supervised': 445, 'full': 446, 'stack': 447, 'developer': 448, 'inverse': 449, 'containing': 450, 'givens': 451, 'rotation': 452, 'eigenvalue': 453, 'takes': 454, 'search': 455, 'payment': 456, 'elements': 457, 'append': 458, 'menus': 459, 'take': 460, 'do': 461, 'styles': 462, 'receive': 463, 'shape': 464, 'verify': 465, 'assert': 466, 'document': 467, 'photo': 468, 'png': 469, 'run': 470, 'natural': 471, 'processing': 472, 'python': 473, 'control': 474, 'continuous': 475, 'integration': 476, 'unsupervised': 477, 'debugging': 478, 'decomposition': 479, 'consisting': 480, 'jacobi': 481, 'loan': 482, 'wishlist': 483, 'username': 484, 'routes': 485, 'templates': 486, 'attributes': 487, 'object': 488, 'sessions': 489, 'outcome': 490, 'solution': 491, 'fields': 492, 'sample': 493, 'format': 494, 'welcome': 495, 'program': 496, 'diagrams': 497, 'close': 498, 'single': 499, 'fixed': 500, 'y': 501, 'front': 502, 'analysis': 503, 'unit': 504, 'testing': 505, 'openai': 506, 'gpt': 507, 'command': 508, 'reinforcement': 509, 'speech': 510, 'recognition': 511, 'rotate': 512, 'householder': 513, 'comprising': 514, 'requires': 515, 'svd': 516, 'button': 517, 'invoice': 518, 'visualization': 519, 'values': 520, 'label': 521, 'ratings': 522, 'stats': 523, 'responses': 524, 'dns': 525, 'smallest': 526, 'response': 527, 'headers': 528, 'length': 529, 'answer': 530, 'error': 531, 'between': 532, 'ensure': 533, 'manual': 534, 'doc': 535, 'audio': 536, 'databases': 537, 'photos': 538, 'launch': 539, 'paste': 540, 'revoke': 541, 'reset': 542, 'block': 543, 'begin': 544, 'typo': 545, 'artificial': 546, 'intelligence': 547, 'machine': 548, 'x': 549, 'computer': 550, 'vision': 551, 'information': 552, 'technology': 553, 'rayleigh': 554, 'quotient': 555, 'gram': 556, 'schmidt': 557, 'transformation': 558, 'person': 559, 'view': 560, 'quest': 561, 'shipment': 562, 'js': 563, 'logs': 564, 'nodes': 565, 'least': 566, 'training': 567, 'reviews': 568, 'skill': 569, 'samples': 570, 'eliminate': 571, 'measurement': 572, 'entry': 573, 'orders': 574, 'observations': 575, 'requests': 576, 'variables': 577, 'points': 578, 'sets': 579, 'profiles': 580, 'leaderboard': 581, 'ranks': 582, 'header': 583, 'endpoints': 584, 'mask': 585, 'mathlib': 586, 'documents': 587, 'configs': 588, 'optimize': 589, 'placeholder': 590, 'resolved': 591, 'conflict': 592, 'scope': 593, 'n': 594, 'graphical': 595, 'cofactor': 596, 'eigenvector': 597, 'shuffle': 598, 'split': 599, 'fibonacci': 600, 'determinant': 601, 'enemy': 602, 'dataset': 603, 'manager': 604, 'achievement': 605, 'usernames': 606, 'scores': 607, 'ages': 608, 'instances': 609, 'reports': 610, 'codes': 611, 'weapons': 612, 'results': 613, 'highest': 614, 'largest': 615, 'maximum': 616, 'quests': 617, 'wishlists': 618, 'rid': 619, 'entries': 620, 'summation': 621, 'dialog': 622, 'boxes': 623, 'epochs': 624, 'dates': 625, 'addresses': 626, 'dialogs': 627, 'payments': 628, 'components': 629, 'packets': 630, 'batches': 631, 'skills': 632, 'request': 633, 'experience': 634, 'countries': 635, 'coefficients': 636, 'enemies': 637, 'oriented': 638, 'lease': 639, 'betweeen': 640, 'your': 641, 'failed': 642, 'statement': 643, 'passed': 644, 'semi': 645, 'utils': 646, 'sortlib': 647, 'cipherlib': 648, 'queuelib': 649, 'react': 650, 'probability': 651, 'jsonlib': 652, 'spreadsheets': 653, 'presentations': 654, 'manuals': 655, 'archives': 656, 'focus': 657, 'terminate': 658, 'temporary': 659, 'process': 660, 'warning': 661, 'handle': 662, 'refactored': 663, 'changed': 664, 'initial': 665, 'tests': 666, 'merged': 667, 'rebased': 668, 'branch': 669, 'optimized': 670, 't': 671, 'u': 672, 'q': 673, 'p': 674, 'z': 675, 'merge': 676, 'rank': 677, 'prime': 678, 'router': 679, 'gateway': 680, 'customerreview': 681, 'filewriter': 682, 'middleware': 683, 'preprocessor': 684, 'radiobutton': 685, 'httprequest': 686, 'slider': 687, 'httpresponse': 688, 'equation': 689, 'ids': 690, 'amounts': 691, 'history': 692, 'epoch': 693, 'datasets': 694, 'biggest': 695, 'financial': 696, 'statements': 697, 'model': 698, 'lowest': 699, 'buttons': 700, 'minimum': 701, 'icon': 702, 'erase': 703, 'investments': 704, 'frequencies': 705, 'messages': 706, 'coordinate': 707, 'features': 708, 'aggregate': 709, 'ip': 710, 'labels': 711, 'weights': 712, 'achievements': 713, 'biases': 714, 'dropdowns': 715, 'layout': 716, 'vector': 717, 'packet': 718, 'vectors': 719, 'cities': 720, 'game': 721, 'levels': 722, 'window': 723, 'accounts': 724, 'api': 725, 'categories': 726, 'budgets': 727, 'windows': 728, 'inventories': 729, 'expenses': 730, 'weight': 731, 'matrix': 732, 'series': 733, 'leaderboards': 734, 'menu': 735, 'players': 736, 'radiobuttons': 737, 'types': 738, 'sliders': 739, 'bias': 740, 'connection': 741, 'pool': 742, 'events': 743, 'objects': 744, 'loss': 745, 'times': 746, 'predictions': 747, 'layers': 748, 'invoices': 749, 'discounts': 750, 'give': 751, 'fill': 752, 'there': 753, 's': 754, 'core': 755, 'dsautils': 756, 'common': 757, 'securitytoolkit': 758, 'pandas': 759, 'geometry': 760, 'vue': 761, 'guimodule': 762, 'mlutils': 763, 'uiutils': 764, 'pydata': 765, 'django': 766, 'filesystem': 767, 'helpers': 768, 'shared': 769, 'websocketlib': 770, 'excellib': 771, 'parserlib': 772, 'decryption': 773, 'datastructures': 774, 'scicalc': 775, 'dateutils': 776, 'templateengine': 777, 'summaries': 778, 'images': 779, 'license': 780, 'timezone': 781, 'refactor': 782, 'todo': 783, 'necessary': 784, 'libraries': 785, 'client': 786, 'execute': 787, 'sql': 788, 'query': 789, 'fixme': 790, 'send': 791, 'through': 792, 'comments': 793, 'improved': 794, 'performance': 795, 'bug': 796}\n",
      "Vocabulary Size: 797\n",
      "Shape of Input Sequence (# of examples, longest sequence length): (2916, 20)\n",
      "Sample Input Sequence: [  0   0   0   0   0   0   0   0   0   0   0   0   0  31 100  62  18 138\n",
      "   3  29]\n"
     ]
    }
   ],
   "source": [
    "# create a tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<unk>')\n",
    "\n",
    "# fit the tokenizer on the corpus -> updates internal vocabulary based on corpus\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "# convert the corpus to sequences of integers -> each word is replaced by its index in the vocabulary for each sentence\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "# pad the sequences to the same length -> add padding tokens to the beginning of each sequence to fit the longest sequence\n",
    "padded_sequences = keras.preprocessing.sequence.pad_sequences(sequences, padding='pre')\n",
    "\n",
    "# get the number of unique words (vocabulary size)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# print the tokenizer properties\n",
    "print('Vocabulary:', tokenizer.word_index)\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Shape of Input Sequence (# of examples, longest sequence length):', padded_sequences.shape)\n",
    "print('Sample Input Sequence:', padded_sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Feature Extraction\n",
    "map intents to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Variable Declaration', 1: 'Constant Declaration', 2: 'Function Declaration', 3: 'Class Declaration', 4: 'Assignment Operation', 5: 'Conditional Statement', 6: 'For Loop', 7: 'While Loop', 8: 'Array Operation', 9: 'Bitwise Operation', 10: 'Mathematical Operation', 11: 'Membership Operation', 12: 'Casting', 13: 'Input', 14: 'Output', 15: 'Assertion', 16: 'Libraries', 17: 'File System', 18: 'IDE Operation', 19: 'Comment', 20: 'Activate Mouse', 21: 'Activate Interactive', 22: 'Interactive Commands', 23: 'Git Operation', 24: 'Exit Block', 25: 'Mouse Click'}\n",
      "Categorial vector shape: (2916, 26)\n"
     ]
    }
   ],
   "source": [
    "# dictionary that maps each intent to a unique index\n",
    "intent_to_index = {intent: index for index, intent in enumerate(unique_intents)}\n",
    "\n",
    "# list for each sentence mapped to its corresponding intent index \n",
    "corpus_intent_mapped_to_index = [intent_to_index[intent] for intent in corpus_intents]\n",
    "\n",
    "# the number of classes to classify a sentence into\n",
    "number_of_classes = len(intent_to_index)\n",
    "\n",
    "# convert intent_to_index to index_to_intent \n",
    "index_to_intent = {index: intent for intent, index in intent_to_index.items()} \n",
    "\n",
    "print(index_to_intent)\n",
    "\n",
    "# one hot encoding for the intents -> length of each vector is equal to the number of classes\n",
    "# each sequence in the dataset is represented as a one-hot encoded vector that represents the intent of the sequence\n",
    "targets = keras.utils.to_categorical(corpus_intent_mapped_to_index, number_of_classes)\n",
    "\n",
    "print('Categorial vector shape:', targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 2332\n",
      "Number of testing examples: 584\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(padded_sequences, targets, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "train_data = list(zip(x_train, y_train))\n",
    "test_data = list(zip(x_test, y_test))\n",
    "\n",
    "print('Number of training examples:', len(train_data))\n",
    "print('Number of testing examples:', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Dimension: 26, Output Dimension: 26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the input is the the padded sequences with the target value being the one-hot encoded intents\n",
    "input_dimenstion = len(unique_intents)\n",
    "\n",
    "# the output is the one-hot encoded intents\n",
    "output_dimenstion = targets.shape[1]\n",
    "\n",
    "print(f\"Input Dimension: {input_dimenstion}, Output Dimension: {output_dimenstion}\")\n",
    "\n",
    "# Model description\n",
    "# The model is a sequential model that consists of:\n",
    "# 1. An embedding layer that converts the input sequences to dense vectors of fixed size\n",
    "# 2. A Bidirectional LSTM layer that processes the input sequences in both directions\n",
    "# 3. A Dense layer with 64 units and ReLU activation function\n",
    "# 4. A Dropout layer with a dropout rate of 0.5\n",
    "# 5. A Dense layer with the output dimension and softmax activation function for multi-class classification\n",
    "\n",
    "# define parameters\n",
    "epochs = 100\n",
    "\n",
    "# the embedding dimension is the size of the vector for which each word is represented\n",
    "# the embedding layer of a neural network, output_dim refers to the size of the dense vectors that the layer will generate for each input token (word). \n",
    "# essentially, it is the number of dimensions in which each word will be represented.\n",
    "embedding_dimension = 150\n",
    "\n",
    "# lstm units\n",
    "lstm_units = 64\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dimension),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(lstm_units, dropout=0.2)),\n",
    "    keras.layers.Dense(lstm_units, activation='relu'),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Dense(output_dimenstion, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.1107 - f1_score: 0.0336 - loss: 3.0909 - precision: 0.1620 - recall: 4.0970e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.4189 - f1_score: 0.1602 - loss: 2.0496 - precision: 0.8338 - recall: 0.1841\n",
      "Epoch 3/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.7018 - f1_score: 0.4350 - loss: 1.0478 - precision: 0.9426 - recall: 0.5563\n",
      "Epoch 4/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.8555 - f1_score: 0.6508 - loss: 0.5184 - precision: 0.9454 - recall: 0.7578\n",
      "Epoch 5/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9274 - f1_score: 0.8107 - loss: 0.2924 - precision: 0.9737 - recall: 0.8658\n",
      "Epoch 6/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9414 - f1_score: 0.8775 - loss: 0.2259 - precision: 0.9694 - recall: 0.9064\n",
      "Epoch 7/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9634 - f1_score: 0.8952 - loss: 0.1433 - precision: 0.9849 - recall: 0.9428\n",
      "Epoch 8/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9812 - f1_score: 0.9196 - loss: 0.0913 - precision: 0.9906 - recall: 0.9650\n",
      "Epoch 9/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9804 - f1_score: 0.9447 - loss: 0.0843 - precision: 0.9901 - recall: 0.9701\n",
      "Epoch 10/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9904 - f1_score: 0.9658 - loss: 0.0516 - precision: 0.9930 - recall: 0.9837\n",
      "Epoch 11/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9946 - f1_score: 0.9824 - loss: 0.0409 - precision: 0.9974 - recall: 0.9888\n",
      "Epoch 12/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9925 - f1_score: 0.9727 - loss: 0.0347 - precision: 0.9951 - recall: 0.9904\n",
      "Epoch 13/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9916 - f1_score: 0.9789 - loss: 0.0342 - precision: 0.9956 - recall: 0.9888\n",
      "Epoch 14/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9969 - f1_score: 0.9774 - loss: 0.0270 - precision: 0.9976 - recall: 0.9917\n",
      "Epoch 15/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9919 - f1_score: 0.9574 - loss: 0.0354 - precision: 0.9936 - recall: 0.9886\n",
      "Epoch 16/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.9962 - f1_score: 0.9846 - loss: 0.0207 - precision: 0.9969 - recall: 0.9955\n",
      "Epoch 17/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.9963 - f1_score: 0.9820 - loss: 0.0213 - precision: 0.9968 - recall: 0.9959\n",
      "Epoch 18/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9976 - f1_score: 0.9905 - loss: 0.0155 - precision: 0.9976 - recall: 0.9957\n",
      "Epoch 19/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9973 - f1_score: 0.9868 - loss: 0.0131 - precision: 0.9981 - recall: 0.9967\n",
      "Epoch 20/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9964 - f1_score: 0.9814 - loss: 0.0203 - precision: 0.9969 - recall: 0.9963\n",
      "Epoch 21/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9936 - f1_score: 0.9781 - loss: 0.0369 - precision: 0.9946 - recall: 0.9929\n",
      "Epoch 22/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9993 - f1_score: 0.9917 - loss: 0.0136 - precision: 0.9993 - recall: 0.9982\n",
      "Epoch 23/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9917 - f1_score: 0.9755 - loss: 0.0264 - precision: 0.9924 - recall: 0.9914\n",
      "Epoch 24/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9987 - f1_score: 0.9871 - loss: 0.0123 - precision: 0.9989 - recall: 0.9985\n",
      "Epoch 25/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9989 - f1_score: 0.9784 - loss: 0.0088 - precision: 0.9998 - recall: 0.9989\n",
      "Epoch 26/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9988 - f1_score: 0.9789 - loss: 0.0062 - precision: 0.9990 - recall: 0.9988\n",
      "Epoch 27/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9995 - f1_score: 0.9880 - loss: 0.0069 - precision: 0.9995 - recall: 0.9988\n",
      "Epoch 28/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9993 - f1_score: 0.9880 - loss: 0.0063 - precision: 0.9993 - recall: 0.9993\n",
      "Epoch 29/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9999 - f1_score: 0.9929 - loss: 0.0061 - precision: 1.0000 - recall: 0.9999\n",
      "Epoch 30/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9993 - f1_score: 0.9855 - loss: 0.0073 - precision: 0.9993 - recall: 0.9993\n",
      "Epoch 31/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9999 - f1_score: 0.9841 - loss: 0.0041 - precision: 0.9999 - recall: 0.9994\n",
      "Epoch 32/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9970 - f1_score: 0.9836 - loss: 0.0076 - precision: 0.9977 - recall: 0.9970\n",
      "Epoch 33/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.9966 - f1_score: 0.9854 - loss: 0.0083 - precision: 0.9972 - recall: 0.9966\n",
      "Epoch 34/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9992 - f1_score: 0.9884 - loss: 0.0061 - precision: 0.9994 - recall: 0.9992\n",
      "Epoch 35/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9968 - f1_score: 0.9845 - loss: 0.0096 - precision: 0.9972 - recall: 0.9964\n",
      "Epoch 36/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.9957 - f1_score: 0.9877 - loss: 0.0176 - precision: 0.9964 - recall: 0.9954\n",
      "Epoch 37/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9943 - f1_score: 0.9787 - loss: 0.0228 - precision: 0.9953 - recall: 0.9943\n",
      "Epoch 38/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9973 - f1_score: 0.9855 - loss: 0.0157 - precision: 0.9975 - recall: 0.9968\n",
      "Epoch 39/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9998 - f1_score: 0.9867 - loss: 0.0048 - precision: 0.9998 - recall: 0.9995\n",
      "Epoch 40/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9991 - f1_score: 0.9791 - loss: 0.0058 - precision: 0.9993 - recall: 0.9991\n",
      "Epoch 41/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.9992 - f1_score: 0.9811 - loss: 0.0043 - precision: 0.9993 - recall: 0.9992\n",
      "Epoch 42/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.9995 - f1_score: 0.9899 - loss: 0.0050 - precision: 0.9995 - recall: 0.9984\n",
      "Epoch 43/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9988 - f1_score: 0.9831 - loss: 0.0054 - precision: 0.9988 - recall: 0.9988\n",
      "Epoch 44/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9995 - f1_score: 0.9914 - loss: 0.0033 - precision: 0.9995 - recall: 0.9995\n",
      "Epoch 45/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9985 - f1_score: 0.9881 - loss: 0.0044 - precision: 0.9985 - recall: 0.9985\n",
      "Epoch 46/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9957 - f1_score: 0.9812 - loss: 0.0069 - precision: 0.9964 - recall: 0.9957\n",
      "Epoch 47/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9999 - f1_score: 0.9900 - loss: 0.0035 - precision: 0.9999 - recall: 0.9999\n",
      "Epoch 48/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9991 - f1_score: 0.9892 - loss: 0.0042 - precision: 0.9991 - recall: 0.9990\n",
      "Epoch 49/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9988 - f1_score: 0.9872 - loss: 0.0049 - precision: 0.9988 - recall: 0.9987\n",
      "Epoch 50/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9995 - f1_score: 0.9919 - loss: 0.0054 - precision: 0.9998 - recall: 0.9983\n",
      "Epoch 51/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9991 - f1_score: 0.9806 - loss: 0.0035 - precision: 0.9991 - recall: 0.9991\n",
      "Epoch 52/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9987 - f1_score: 0.9762 - loss: 0.0037 - precision: 0.9987 - recall: 0.9987\n",
      "Epoch 53/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.9960 - f1_score: 0.9873 - loss: 0.0103 - precision: 0.9960 - recall: 0.9958\n",
      "Epoch 54/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9955 - f1_score: 0.9783 - loss: 0.0104 - precision: 0.9962 - recall: 0.9955\n",
      "Epoch 55/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9981 - f1_score: 0.9852 - loss: 0.0054 - precision: 0.9989 - recall: 0.9981\n",
      "Epoch 56/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9996 - f1_score: 0.9787 - loss: 0.0039 - precision: 0.9996 - recall: 0.9989\n",
      "Epoch 57/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9995 - f1_score: 0.9890 - loss: 0.0048 - precision: 0.9995 - recall: 0.9994\n",
      "Epoch 58/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9982 - f1_score: 0.9885 - loss: 0.0059 - precision: 0.9985 - recall: 0.9982\n",
      "Epoch 59/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9999 - f1_score: 0.9875 - loss: 0.0027 - precision: 0.9999 - recall: 0.9999\n",
      "Epoch 60/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9998 - f1_score: 0.9892 - loss: 0.0027 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 61/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9997 - f1_score: 0.9816 - loss: 0.0034 - precision: 0.9997 - recall: 0.9996\n",
      "Epoch 62/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9991 - f1_score: 0.9884 - loss: 0.0026 - precision: 0.9991 - recall: 0.9991\n",
      "Epoch 63/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9999 - f1_score: 0.9896 - loss: 0.0023 - precision: 1.0000 - recall: 0.9999\n",
      "Epoch 64/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9985 - f1_score: 0.9915 - loss: 0.0071 - precision: 0.9985 - recall: 0.9985\n",
      "Epoch 65/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9975 - f1_score: 0.9848 - loss: 0.0088 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 66/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9990 - f1_score: 0.9852 - loss: 0.0035 - precision: 0.9990 - recall: 0.9990\n",
      "Epoch 67/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - f1_score: 0.9934 - loss: 0.0015 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - f1_score: 0.9839 - loss: 0.0014 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9998 - f1_score: 0.9937 - loss: 0.0024 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 70/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9998 - f1_score: 0.9743 - loss: 0.0017 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 71/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9997 - f1_score: 0.9866 - loss: 0.0022 - precision: 0.9997 - recall: 0.9997\n",
      "Epoch 72/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9989 - f1_score: 0.9820 - loss: 0.0059 - precision: 0.9989 - recall: 0.9983\n",
      "Epoch 73/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9995 - f1_score: 0.9836 - loss: 0.0030 - precision: 0.9995 - recall: 0.9995\n",
      "Epoch 74/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9996 - f1_score: 0.9891 - loss: 0.0019 - precision: 0.9996 - recall: 0.9996\n",
      "Epoch 75/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9988 - f1_score: 0.9886 - loss: 0.0069 - precision: 0.9988 - recall: 0.9988\n",
      "Epoch 76/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9978 - f1_score: 0.9842 - loss: 0.0076 - precision: 0.9978 - recall: 0.9978\n",
      "Epoch 77/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9998 - f1_score: 0.9857 - loss: 0.0035 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 78/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9983 - f1_score: 0.9811 - loss: 0.0059 - precision: 0.9983 - recall: 0.9983\n",
      "Epoch 79/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9979 - f1_score: 0.9854 - loss: 0.0066 - precision: 0.9979 - recall: 0.9978\n",
      "Epoch 80/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9976 - f1_score: 0.9865 - loss: 0.0112 - precision: 0.9976 - recall: 0.9976\n",
      "Epoch 81/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9993 - f1_score: 0.9863 - loss: 0.0033 - precision: 0.9993 - recall: 0.9993\n",
      "Epoch 82/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9962 - f1_score: 0.9836 - loss: 0.0075 - precision: 0.9962 - recall: 0.9962\n",
      "Epoch 83/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9995 - f1_score: 0.9832 - loss: 0.0033 - precision: 0.9995 - recall: 0.9995\n",
      "Epoch 84/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9990 - f1_score: 0.9881 - loss: 0.0038 - precision: 0.9990 - recall: 0.9988\n",
      "Epoch 85/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9989 - f1_score: 0.9840 - loss: 0.0032 - precision: 0.9993 - recall: 0.9989\n",
      "Epoch 86/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9991 - f1_score: 0.9792 - loss: 0.0039 - precision: 0.9995 - recall: 0.9991\n",
      "Epoch 87/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9989 - f1_score: 0.9917 - loss: 0.0046 - precision: 0.9989 - recall: 0.9989\n",
      "Epoch 88/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9998 - f1_score: 0.9900 - loss: 0.0016 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 89/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9993 - f1_score: 0.9860 - loss: 0.0027 - precision: 0.9993 - recall: 0.9993\n",
      "Epoch 90/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 1.0000 - f1_score: 0.9901 - loss: 9.0628e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9995 - f1_score: 0.9911 - loss: 0.0012 - precision: 0.9995 - recall: 0.9995\n",
      "Epoch 92/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9995 - f1_score: 0.9922 - loss: 0.0016 - precision: 0.9995 - recall: 0.9995\n",
      "Epoch 93/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9999 - f1_score: 0.9838 - loss: 7.5324e-04 - precision: 0.9999 - recall: 0.9999\n",
      "Epoch 94/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9996 - f1_score: 0.9882 - loss: 0.0022 - precision: 0.9996 - recall: 0.9996\n",
      "Epoch 95/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9985 - f1_score: 0.9902 - loss: 0.0033 - precision: 0.9985 - recall: 0.9985\n",
      "Epoch 96/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.9994 - f1_score: 0.9905 - loss: 0.0013 - precision: 0.9994 - recall: 0.9994\n",
      "Epoch 97/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.9993 - f1_score: 0.9884 - loss: 0.0018 - precision: 0.9993 - recall: 0.9993\n",
      "Epoch 98/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9997 - f1_score: 0.9854 - loss: 0.0012 - precision: 0.9997 - recall: 0.9997\n",
      "Epoch 99/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9973 - f1_score: 0.9858 - loss: 0.0046 - precision: 0.9973 - recall: 0.9973\n",
      "Epoch 100/100\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9996 - f1_score: 0.9878 - loss: 7.5177e-04 - precision: 0.9996 - recall: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a1d588abc0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_sequences, targets, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Model Input Shape:\", model.input_shape)\n",
    "# print(\"X_test shape\", x_test.shape)\n",
    "# print(x_test.dtype)\n",
    "# print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a simple prediction with a smaller subset\n",
    "# sample_input = x_test[:1]  # Take a single sample\n",
    "# print(\"Sample input shape:\", sample_input.shape)\n",
    "# print(\"Sample input shape:\", sample_input.shape)\n",
    "# sample_prediction = model.predict(sample_input)\n",
    "# print(\"Sample prediction:\", sample_prediction)\n",
    "\n",
    "# # Check the model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     predictions = model.predict(x_test)\n",
    "#     print(\"Predictions shape:\", predictions.shape)\n",
    "# except Exception as e:\n",
    "#     print(\"Error during prediction on entire dataset:\", e)\n",
    "# print(\"Checking for NaNs in x_test:\", np.isnan(x_test).any())\n",
    "# print(\"Checking for infs in x_test:\", np.isinf(x_test).any())\n",
    "# print(\"x_test mean:\", np.mean(x_test))\n",
    "# print(\"x_test std deviation:\", np.std(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# for test_example in x_test:\n",
    "#     test_example = test_example.reshape(1, -1)\n",
    "#     print(\"Test example shape:\", test_example.shape)\n",
    "#     predictions = model.predict(test_example)\n",
    "\n",
    "# print(x_test.shape)\n",
    "# # x_test = x_test.reshape(x_test.shape[0], x_test.shape[1])\n",
    "# # print(x_test.shape)\n",
    "# # print(x_test.reshape(1, -1).shape)\n",
    "# # x_test_final = []\n",
    "# # for test in x_test:\n",
    "# #     test = test.reshape(1, -1)\n",
    "# #     print(test.shape)\n",
    "# #     x_test_final.append(test)\n",
    "\n",
    "# # print(\"X_test_final shape:\", x_test_final[0].shape)\n",
    "\n",
    "# print(x_test[0])\n",
    "# print(x_test[:1])\n",
    "# print(x_test[:1].shape)\n",
    "\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_test.shape)\n",
    "# # x_test = x_test.reshape(1, -1)\n",
    "# predictions = []\n",
    "# for test in x_test:\n",
    "#     test = test.reshape(1, -1)\n",
    "#     print(test.shape)\n",
    "#     predictions.append(model.predict(test))\n",
    "# # predictions = model.predict(x_test, verbose=1)\n",
    "\n",
    "# predicted_intents = [index_to_intent[np.argmax(prediction)] for prediction in predictions]\n",
    "# true_intents = [index_to_intent[np.argmax(intent)] for intent in y_test]\n",
    "\n",
    "\n",
    "# accuracy = accuracy_score(true_intents, predicted_intents)\n",
    "# precision = precision_score(true_intents, predicted_intents, average='weighted')\n",
    "# recall = recall_score(true_intents, predicted_intents, average='weighted')\n",
    "# f1 = f1_score(true_intents, predicted_intents, average='weighted')\n",
    "\n",
    "# # print('Accuracy:', accuracy)\n",
    "# print('Precision:', precision)\n",
    "# print('Recall:', recall)\n",
    "# print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted Intent: Input\n"
     ]
    }
   ],
   "source": [
    "user = input(\"Sentence:\")\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences([user])\n",
    "\n",
    "test_padded_sequences = keras.preprocessing.sequence.pad_sequences(test_sequences, padding='pre')\n",
    "\n",
    "predictions = model.predict(test_padded_sequences)\n",
    "\n",
    "predicted_intent_index = np.argmax(predictions)\n",
    "\n",
    "predicted_intent = index_to_intent[predicted_intent_index]\n",
    "\n",
    "print(f\"Predicted Intent: {predicted_intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./models/full_intent_detection_model.h5\")\n",
    "model.save(\"./models/full_intent_detection_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import tf2onnx\n",
    "\n",
    "# # Load your TensorFlow model\n",
    "# model = tf.keras.models.load_model('models\\intent_detection_model.keras')\n",
    "\n",
    "# # Convert the model to ONNX format\n",
    "# spec = (tf.TensorSpec((None, *model.input_shape[1:]), tf.float32, name=\"input\"),)\n",
    "# output_path = \"../models/intent_detection.onnx\"\n",
    "# model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, output_path=output_path)\n",
    "\n",
    "# # Save the ONNX model\n",
    "# with open(output_path, \"wb\") as f:\n",
    "#     f.write(model_proto.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import tf2onnx\n",
    "# import numpy as np\n",
    "\n",
    "# # Define or load your Sequential model\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Dense(10, activation='relu', input_shape=(784,)),\n",
    "#     tf.keras.layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # Provide a dummy input to the model for shape inference\n",
    "# spec = (tf.TensorSpec((None, 784), tf.float32, name=\"input\"),)\n",
    "\n",
    "# # Convert the model to ONNX format\n",
    "# output_path = \"path/to/save/model.onnx\"\n",
    "# # model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, output_path=output_path)\n",
    "# model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, output_path=output_path)\n",
    "\n",
    "# # Save the ONNX model\n",
    "# with open(output_path, \"wb\") as f:\n",
    "#     f.write(model_proto.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step\n",
      "Predicted Intent: Output\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('models/intent_detection_model_2.h5')\n",
    "\n",
    "user_input = 'output the variable name to the user'\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences([user_input])\n",
    "\n",
    "test_padded_sequences = keras.preprocessing.sequence.pad_sequences(test_sequences, padding='pre')\n",
    "\n",
    "predictions = loaded_model.predict(test_padded_sequences)\n",
    "\n",
    "predicted_intent_index = np.argmax(predictions)\n",
    "\n",
    "predicted_intent = index_to_intent[predicted_intent_index]\n",
    "\n",
    "print(f\"Predicted Intent: {predicted_intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('models/full_intent_detection_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Predicted Intent: Bitwise Operation\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Predicted Intent: Bitwise Operation\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Predicted Intent: Bitwise Operation\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Predicted Intent: Bitwise Operation\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Predicted Intent: Bitwise Operation\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Predicted Intent: Bitwise Operation\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Predicted Intent: Mathematical Operation\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Predicted Intent: Mathematical Operation\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Predicted Intent: Mathematical Operation\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Predicted Intent: Bitwise Operation\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Predicted Intent: Bitwise Operation\n"
     ]
    }
   ],
   "source": [
    "sentences =[\n",
    "    \"bitwise x and y\",\n",
    "    \"bitwise x or y\",\n",
    "    \"perform bitwise and on number and 10\",\n",
    "    \"perform bitwise or on number and 10\",\n",
    "    \"shift left x by 2\",\n",
    "    \"shift right x by 2\",\n",
    "    \"shift x left by 2\",\n",
    "    \"shift x right by 2\",\n",
    "    \"xor x and y\",\n",
    "    \"perform bitwise xor on x and y\",\n",
    "    \"perform bitwise xor on x and 10\"\n",
    "]\n",
    "for sentence in sentences:\n",
    "    test_sequences = tokenizer.texts_to_sequences([sentence])\n",
    "\n",
    "    test_padded_sequences = keras.preprocessing.sequence.pad_sequences(test_sequences, padding='pre')\n",
    "\n",
    "    predictions = loaded_model.predict(test_padded_sequences)\n",
    "\n",
    "    predicted_intent_index = np.argmax(predictions)\n",
    "\n",
    "    predicted_intent = index_to_intent[predicted_intent_index]\n",
    "\n",
    "    print(f\"Predicted Intent: {predicted_intent}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
