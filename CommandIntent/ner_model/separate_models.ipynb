{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1df91e05ab0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# from bilstm_crf import BiLSTMCRF\n",
    "from torch import optim\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "# import evaluation metrics \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from TorchCRF import CRF\n",
    "\n",
    "class BiLSTMCRF(nn.Module):\n",
    "    def __init__(self, vocab_size, word_embedding_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "        # hyperparameters\n",
    "        self.word_embedding_dim = word_embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # model layers\n",
    "        self.word_embedding = nn.Embedding(vocab_size, word_embedding_dim)\n",
    "        self.lstm = nn.LSTM(word_embedding_dim, hidden_dim // 2, bidirectional=True, dropout=0.2)\n",
    "        self.hidden_to_tag = nn.Linear(hidden_dim, output_dim)\n",
    "        self.crf = CRF(output_dim)\n",
    "\n",
    "    def __init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2), torch.randn(2, 1, self.hidden_dim // 2)) # initialize hidden state\n",
    "\n",
    "    def __get_lstm_features(self, sentence):\n",
    "        self.hidden = self.__init_hidden()\n",
    "        word_embeddings = self.word_embedding(sentence).view(len(sentence), 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(word_embeddings, self.hidden)\n",
    "        lstm_features = self.hidden_to_tag(lstm_out)\n",
    "        return lstm_features\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        features = self.__get_lstm_features(sentence) # emissions from the lstm layer\n",
    "        tags = tags.view(-1, 1)\n",
    "        loss = -self.crf(features, tags)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        lstm_features = self.__get_lstm_features(sentence) # emissions from the lstm layer\n",
    "        tag_sequence = self.crf.decode(lstm_features)\n",
    "        return tag_sequence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    data = pd.read_csv('../ner_dataset/ner_dataset.csv', encoding='latin1')\n",
    "\n",
    "    # remove white spaces from column names\n",
    "    data.columns = data.columns.str.strip()\n",
    "\n",
    "    print(data.columns)\n",
    "    # Group by 'Sentence #' and aggregate\n",
    "    grouped_data = data.groupby('Sentence #').agg({\n",
    "        'Word': lambda x: ''.join(x),  # Join words into a single sentence\n",
    "        'Tag': lambda x: list(x.str.strip()),       # Collect tags into a list\n",
    "        'Intent': lambda x: list(x.str.strip().str.replace('_', ' '))     # Collect intents into a list\n",
    "    }).reset_index()  # Reset index to make 'Sentence #' a regular column\n",
    "\n",
    "    return data, grouped_data\n",
    "\n",
    "\n",
    "def prepare_data(dataframe):\n",
    "    dataset = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        sentence = row['Word'][1:]\n",
    "        tags = row['Tag']\n",
    "        intents = row['Intent']\n",
    "        dataset.append((sentence, tags, intents[0]))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sentence #', 'Word', 'Tag', 'Intent'], dtype='object')\n",
      "[' array operation' ' assertion' ' assignment operation'\n",
      " ' bitwise operation' ' casting' ' class declaration' ' comment'\n",
      " ' conditional operation' ' constant declaration' ' file system'\n",
      " ' for loop' ' function declaration' ' git operation' ' ide operation'\n",
      " ' input' ' interactive commands' ' libraries' ' mathematical operation'\n",
      " ' membership operation' ' output' ' variable declaration' ' while loop']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>append the value 12345.6789 to the list packe...</td>\n",
       "      <td>[B-OPERATION, O, O, B-ELEMENT, O, O, B-ARRAY, ...</td>\n",
       "      <td>[array operation, array operation, array opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>push the value false to the list inventories</td>\n",
       "      <td>[B-OPERATION, O, O, B-ELEMENT, O, O, O, B-ARRAY]</td>\n",
       "      <td>[array operation, array operation, array opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>append the value -456 to the array player scores</td>\n",
       "      <td>[B-OPERATION, O, O, B-ELEMENT, O, O, O, B-ARRA...</td>\n",
       "      <td>[array operation, array operation, array opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>push the value 3.14159 to the list links</td>\n",
       "      <td>[B-OPERATION, O, O, B-ELEMENT, O, O, O, B-ARRAY]</td>\n",
       "      <td>[array operation, array operation, array opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>include the value Back End Development to the...</td>\n",
       "      <td>[B-OPERATION, O, O, B-ELEMENT, I-ELEMENT, I-EL...</td>\n",
       "      <td>[array operation, array operation, array opera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence #                                               Word   \n",
       "0           0   append the value 12345.6789 to the list packe...  \\\n",
       "1           1       push the value false to the list inventories   \n",
       "2           2   append the value -456 to the array player scores   \n",
       "3           3           push the value 3.14159 to the list links   \n",
       "4           4   include the value Back End Development to the...   \n",
       "\n",
       "                                                 Tag   \n",
       "0  [B-OPERATION, O, O, B-ELEMENT, O, O, B-ARRAY, ...  \\\n",
       "1   [B-OPERATION, O, O, B-ELEMENT, O, O, O, B-ARRAY]   \n",
       "2  [B-OPERATION, O, O, B-ELEMENT, O, O, O, B-ARRA...   \n",
       "3   [B-OPERATION, O, O, B-ELEMENT, O, O, O, B-ARRAY]   \n",
       "4  [B-OPERATION, O, O, B-ELEMENT, I-ELEMENT, I-EL...   \n",
       "\n",
       "                                              Intent  \n",
       "0  [array operation, array operation, array opera...  \n",
       "1  [array operation, array operation, array opera...  \n",
       "2  [array operation, array operation, array opera...  \n",
       "3  [array operation, array operation, array opera...  \n",
       "4  [array operation, array operation, array opera...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format data\n",
    "data, goruped_data = read_dataset()\n",
    "print(data[\"Intent\"].unique())\n",
    "\n",
    "goruped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'array operation',\n",
       " 'assertion',\n",
       " 'assignment operation',\n",
       " 'bitwise operation',\n",
       " 'casting',\n",
       " 'class declaration',\n",
       " 'comment',\n",
       " 'conditional operation',\n",
       " 'constant declaration',\n",
       " 'file system',\n",
       " 'for loop',\n",
       " 'function declaration',\n",
       " 'git operation',\n",
       " 'ide operation',\n",
       " 'input',\n",
       " 'interactive commands',\n",
       " 'libraries',\n",
       " 'mathematical operation',\n",
       " 'membership operation',\n",
       " 'output',\n",
       " 'variable declaration',\n",
       " 'while loop'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = prepare_data(goruped_data)\n",
    "\n",
    "sentences = [sentence for sentence, _, _ in training_data]\n",
    "tags = [tag for _, tag, _ in training_data]\n",
    "intents = set([intent for _, _, intent in training_data])\n",
    "\n",
    "intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent: assignment operation\n",
      "Number of sentences: 80\n",
      "Example: ('end date equals clustering algorithms', ['B-LHS', 'I-LHS', 'O', 'B-RHS', 'I-RHS'])\n",
      "\n",
      "\n",
      "Intent: git operation\n",
      "Number of sentences: 80\n",
      "Example: ('stage', ['B-ACTION'])\n",
      "\n",
      "\n",
      "Intent: interactive commands\n",
      "Number of sentences: 220\n",
      "Example: ('go get all the files in the project', ['O', 'O', 'O', 'O', 'B-TYPE', 'O', 'O', 'O'])\n",
      "\n",
      "\n",
      "Intent: bitwise operation\n",
      "Number of sentences: 97\n",
      "Example: ('perform a bitwise xor on creation date and 150', ['O', 'O', 'O', 'B-OPERATOR', 'O', 'B-OPERAND', 'I-OPERAND', 'O', 'B-OPERAND'])\n",
      "\n",
      "\n",
      "Intent: for loop\n",
      "Number of sentences: 120\n",
      "Example: ('create a for loop from -30 to -10 with variable item', ['O', 'O', 'O', 'O', 'O', 'B-START', 'O', 'B-END', 'O', 'O', 'B-VAR'])\n",
      "\n",
      "\n",
      "Intent: ide operation\n",
      "Number of sentences: 290\n",
      "Example: ('launch terminal', ['B-ACTION', 'B-TYPE'])\n",
      "\n",
      "\n",
      "Intent: comment\n",
      "Number of sentences: 50\n",
      "Example: ('add a this is a log comment', ['O', 'I-COMMENT', 'I-COMMENT', 'I-COMMENT', 'O', 'I-COMMENT', 'O'])\n",
      "\n",
      "\n",
      "Intent: constant declaration\n",
      "Number of sentences: 200\n",
      "Example: ('make constant element as string and initialize it with -80808', ['O', 'O', 'B-VAR', 'O', 'B-TYPE', 'O', 'O', 'O', 'O', 'B-VAL'])\n",
      "\n",
      "\n",
      "Intent: conditional operation\n",
      "Number of sentences: 160\n",
      "Example: ('whether j less than -2020202', ['O', 'B-LHS', 'B-CONDITION', 'I-CONDITION', 'B-RHS'])\n",
      "\n",
      "\n",
      "Intent: assertion\n",
      "Number of sentences: 49\n",
      "Example: ('verify that data is less than or equal Debugging Session', ['O', 'O', 'B-VAR', 'O', 'B-CONDITION', 'I-CONDITION', 'I-CONDITION', 'I-CONDITION', 'B-VAL', 'I-VAL'])\n",
      "\n",
      "\n",
      "Intent: variable declaration\n",
      "Number of sentences: 240\n",
      "Example: ('make start time as double and initialize 0.000123', ['O', 'B-VAR', 'I-VAR', 'O', 'B-TYPE', 'O', 'O', 'B-VAL'])\n",
      "\n",
      "\n",
      "Intent: function declaration\n",
      "Number of sentences: 112\n",
      "Example: ('write a procedure named rayleigh quotient iteration algorithm', ['O', 'O', 'O', 'O', 'B-FUNC', 'I-FUNC', 'I-FUNC', 'I-FUNC'])\n",
      "\n",
      "\n",
      "Intent: class declaration\n",
      "Number of sentences: 38\n",
      "Example: ('make a class with the name Score', ['O', 'O', 'O', 'O', 'O', 'O', 'B-CLASS'])\n",
      "\n",
      "\n",
      "Intent: libraries\n",
      "Number of sentences: 51\n",
      "Example: ('import the library QtLib', ['O', 'O', 'O', 'B-LIB_NAME'])\n",
      "\n",
      "\n",
      "Intent: while loop\n",
      "Number of sentences: 60\n",
      "Example: ('write a while loop to iterate while app config is not equal environment', ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LHS', 'I-LHS', 'B-CONDITION', 'I-CONDITION', 'I-CONDITION', 'B-RHS'])\n",
      "\n",
      "\n",
      "Intent: casting\n",
      "Number of sentences: 78\n",
      "Example: ('make budget allocation to int', ['O', 'B-VAR', 'I-VAR', 'O', 'B-TYPE'])\n",
      "\n",
      "\n",
      "Intent: membership operation\n",
      "Number of sentences: 114\n",
      "Example: ('check whether item array is in set middleware stack', ['O', 'O', 'B-ELEMENT', 'O', 'O', 'B-CONDITION', 'O', 'B-COLLECTION', 'I-COLLECTION'])\n",
      "\n",
      "\n",
      "Intent: output\n",
      "Number of sentences: 120\n",
      "Example: ('output the variable max value', ['O', 'O', 'O', 'B-VAR', 'I-VAR'])\n",
      "\n",
      "\n",
      "Intent: array operation\n",
      "Number of sentences: 139\n",
      "Example: ('append the value 12345.6789 to the list packet list', ['B-OPERATION', 'O', 'O', 'B-ELEMENT', 'O', 'O', 'B-ARRAY', 'I-ARRAY', 'O'])\n",
      "\n",
      "\n",
      "Intent: mathematical operation\n",
      "Number of sentences: 370\n",
      "Example: ('divide order queue and j', ['B-OPERATOR', 'B-OPERAND', 'I-OPERAND', 'O', 'B-OPERAND'])\n",
      "\n",
      "\n",
      "Intent: file system\n",
      "Number of sentences: 150\n",
      "Example: ('change name', ['B-ACTION', 'I-ACTION'])\n",
      "\n",
      "\n",
      "Intent: input\n",
      "Number of sentences: 50\n",
      "Example: ('enter from the user with message Enter a value and put it to k', ['O', 'O', 'O', 'O', 'O', 'O', 'B-MESSAGE', 'I-MESSAGE', 'I-MESSAGE', 'O', 'O', 'O', 'O', 'B-VAR'])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "separate_data = {} # a dictionary to store the data for each intent\n",
    "\n",
    "# separate training data by intent\n",
    "for intent in intents:\n",
    "    separate_data[intent] = [(sentence, tag) for sentence, tag, _intent in training_data if _intent == intent]\n",
    "\n",
    "for intent in separate_data:\n",
    "    print(f'Intent: {intent}')\n",
    "    print(f'Number of sentences: {len(separate_data[intent])}')\n",
    "    print(f'Example: {separate_data[intent][0]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent: assignment operation\n",
      "Number of unique words: 178\n",
      "Number of unique tags: 6\n",
      "\n",
      "\n",
      "Intent: git operation\n",
      "Number of unique words: 36\n",
      "Number of unique tags: 5\n",
      "\n",
      "\n",
      "Intent: interactive commands\n",
      "Number of unique words: 22\n",
      "Number of unique tags: 3\n",
      "\n",
      "\n",
      "Intent: bitwise operation\n",
      "Number of unique words: 144\n",
      "Number of unique tags: 6\n",
      "\n",
      "\n",
      "Intent: for loop\n",
      "Number of unique words: 141\n",
      "Number of unique tags: 9\n",
      "\n",
      "\n",
      "Intent: ide operation\n",
      "Number of unique words: 134\n",
      "Number of unique tags: 7\n",
      "\n",
      "\n",
      "Intent: comment\n",
      "Number of unique words: 59\n",
      "Number of unique tags: 4\n",
      "\n",
      "\n",
      "Intent: constant declaration\n",
      "Number of unique words: 305\n",
      "Number of unique tags: 7\n",
      "\n",
      "\n",
      "Intent: conditional operation\n",
      "Number of unique words: 283\n",
      "Number of unique tags: 9\n",
      "\n",
      "\n",
      "Intent: assertion\n",
      "Number of unique words: 117\n",
      "Number of unique tags: 8\n",
      "\n",
      "\n",
      "Intent: variable declaration\n",
      "Number of unique words: 299\n",
      "Number of unique tags: 7\n",
      "\n",
      "\n",
      "Intent: function declaration\n",
      "Number of unique words: 173\n",
      "Number of unique tags: 7\n",
      "\n",
      "\n",
      "Intent: class declaration\n",
      "Number of unique words: 58\n",
      "Number of unique tags: 4\n",
      "\n",
      "\n",
      "Intent: libraries\n",
      "Number of unique words: 49\n",
      "Number of unique tags: 3\n",
      "\n",
      "\n",
      "Intent: while loop\n",
      "Number of unique words: 100\n",
      "Number of unique tags: 8\n",
      "\n",
      "\n",
      "Intent: casting\n",
      "Number of unique words: 112\n",
      "Number of unique tags: 5\n",
      "\n",
      "\n",
      "Intent: membership operation\n",
      "Number of unique words: 249\n",
      "Number of unique tags: 8\n",
      "\n",
      "\n",
      "Intent: output\n",
      "Number of unique words: 110\n",
      "Number of unique tags: 7\n",
      "\n",
      "\n",
      "Intent: array operation\n",
      "Number of unique words: 242\n",
      "Number of unique tags: 8\n",
      "\n",
      "\n",
      "Intent: mathematical operation\n",
      "Number of unique words: 285\n",
      "Number of unique tags: 7\n",
      "\n",
      "\n",
      "Intent: file system\n",
      "Number of unique words: 73\n",
      "Number of unique tags: 5\n",
      "\n",
      "\n",
      "Intent: input\n",
      "Number of unique words: 82\n",
      "Number of unique tags: 6\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "separate_word_to_index = {}\n",
    "separate_tag_to_index = {}\n",
    "separate_index_to_tag = {}\n",
    "\n",
    "for intent in separate_data:\n",
    "    words = [word for sentence, _ in separate_data[intent] for word in sentence.split()]\n",
    "    tags = [tag for _, tag in separate_data[intent] for tag in tag]\n",
    "\n",
    "    word_to_index = {word: i + 1 for i, word in enumerate(set(words))}\n",
    "    tag_to_index = {tag: i + 1 for i, tag in enumerate(set(tags))}\n",
    "\n",
    "    word_to_index['<UNK>'] = 0\n",
    "    tag_to_index['<UNK>'] = 0\n",
    "\n",
    "    separate_word_to_index[intent] = word_to_index\n",
    "    separate_tag_to_index[intent] = tag_to_index\n",
    "\n",
    "separate_index_to_tag = {intent: {i: tag for tag, i in separate_tag_to_index[intent].items()} for intent in separate_tag_to_index}\n",
    "\n",
    "for intent in separate_data:\n",
    "    print(f'Intent: {intent}')\n",
    "    print(f'Number of unique words: {len(separate_word_to_index[intent])}')\n",
    "    print(f'Number of unique tags: {len(separate_tag_to_index[intent])}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'array operation': ['B-ARRAY',\n",
       "  'I-ARRAY',\n",
       "  'B-OPERATION',\n",
       "  'I-OPERATION',\n",
       "  'B-ELEMENT',\n",
       "  'I-ELEMENT',\n",
       "  'O'],\n",
       " 'assertion': ['B-VAR',\n",
       "  'I-VAR',\n",
       "  'B-VAL',\n",
       "  'I-VAL',\n",
       "  'B-CONDITION',\n",
       "  'I-CONDITION',\n",
       "  'O'],\n",
       " 'assignment operation': ['B-LHS', 'I-LHS', 'B-RHS', 'I-RHS', 'O'],\n",
       " 'bitwise operation': ['B-OPERATOR',\n",
       "  'I-OPERATOR',\n",
       "  'B-OPERAND',\n",
       "  'I-OPERAND',\n",
       "  'O'],\n",
       " 'casting': ['B-VAR', 'I-VAR', 'B-TYPE', 'I-TYPE', 'O'],\n",
       " 'class declaration': ['B-CLASS', 'I-CLASS', 'O'],\n",
       " 'comment': ['B-COMMENT', 'I-COMMENT', 'O'],\n",
       " 'conditional operation': ['B-LHS',\n",
       "  'I-LHS',\n",
       "  'B-RHS',\n",
       "  'I-RHS',\n",
       "  'B-CONDITION',\n",
       "  'I-CONDITION',\n",
       "  'B-LOG',\n",
       "  'I-LOG',\n",
       "  'O'],\n",
       " 'constant declaration': ['B-VAR',\n",
       "  'I-VAR',\n",
       "  'B-VAL',\n",
       "  'I-VAL',\n",
       "  'B-TYPE',\n",
       "  'I-TYPE',\n",
       "  'O'],\n",
       " 'file system': ['B-FILE',\n",
       "  'I-FILE',\n",
       "  'B-ACTION',\n",
       "  'I-ACTION',\n",
       "  'B-DIR',\n",
       "  'I-DIR',\n",
       "  'O'],\n",
       " 'for loop': ['B-START',\n",
       "  'I-START',\n",
       "  'B-END',\n",
       "  'I-END',\n",
       "  'B-STEP',\n",
       "  'I-STEP',\n",
       "  'B-VAR',\n",
       "  'I-VAR',\n",
       "  'B-COLLECTION',\n",
       "  'I-COLLECTION',\n",
       "  'O'],\n",
       " 'function declaration': ['B-FUNC',\n",
       "  'I-FUNC',\n",
       "  'B-TYPE',\n",
       "  'I-TYPE',\n",
       "  'B-PARAM',\n",
       "  'I-PARAM',\n",
       "  'O'],\n",
       " 'git operation': ['B-ACTION', 'I-ACTION', 'B-MESSAGE', 'I-MESSAGE', 'O'],\n",
       " 'ide operation': ['B-ACTION',\n",
       "  'I-ACTION',\n",
       "  'B-TYPE',\n",
       "  'I-TYPE',\n",
       "  'B-LINE',\n",
       "  'I-LINE',\n",
       "  'B-FILE',\n",
       "  'I-FILE',\n",
       "  'O'],\n",
       " 'input': ['B-VAR', 'I-VAR', 'B-MESSAGE', 'I-MESSAGE', 'O'],\n",
       " 'interactive commands': ['B-TYPE', 'I-TYPE', 'O'],\n",
       " 'libraries': ['B-LIB_NAME', 'I-LIB_NAME', 'O'],\n",
       " 'mathematical operation': ['B-OPERAND',\n",
       "  'I-OPERAND',\n",
       "  'B-OPERATOR',\n",
       "  'I-OPERATOR',\n",
       "  'B-VAR',\n",
       "  'I-VAR',\n",
       "  'O'],\n",
       " 'membership operation': ['B-ELEMENT',\n",
       "  'I-ELEMENT',\n",
       "  'B-COLLECTION',\n",
       "  'I-COLLECTION',\n",
       "  'B-CONDITION',\n",
       "  'I-CONDITION',\n",
       "  'O'],\n",
       " 'output': ['B-VAR', 'I-VAR', 'B-VAL', 'I-VAL', 'B-MESSAGE', 'I-MESSAGE', 'O'],\n",
       " 'variable declaration': ['B-VAR',\n",
       "  'I-VAR',\n",
       "  'B-VAL',\n",
       "  'I-VAL',\n",
       "  'B-TYPE',\n",
       "  'I-TYPE',\n",
       "  'O'],\n",
       " 'while loop': ['B-LHS',\n",
       "  'I-LHS',\n",
       "  'B-RHS',\n",
       "  'I-RHS',\n",
       "  'B-CONDITION',\n",
       "  'I-CONDITION',\n",
       "  'O']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../ner_dataset/intent_to_tags.json', 'r') as f:\n",
    "    intent_to_tags = json.load(f)\n",
    "\n",
    "final_intent_to_tags = {}\n",
    "\n",
    "for intent in intent_to_tags.keys():\n",
    "    final_intent_to_tags[intent] = []\n",
    "    for tag in intent_to_tags[intent]:\n",
    "        if tag == 'O':\n",
    "            final_intent_to_tags[intent].append(tag)\n",
    "        else:\n",
    "            final_intent_to_tags[intent].append('B-' + tag)\n",
    "            final_intent_to_tags[intent].append('I-' + tag)\n",
    "\n",
    "        \n",
    "final_intent_to_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 72 8 8\n"
     ]
    }
   ],
   "source": [
    "# training data for each intent\n",
    "# training_data = {intent: [x_train, y_train, x_test, y_test]}\n",
    "training_data = {} \n",
    "for intent in separate_data:\n",
    "    sentences = [sentence for sentence, _ in separate_data[intent]]\n",
    "    tags = [tag for _, tag in separate_data[intent]]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(sentences, tags, test_size=0.1, random_state=42)\n",
    "    training_data[intent] = [x_train, y_train, x_test, y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "for intent in final_intent_to_tags.keys():\n",
    "    models[intent] = []\n",
    "    models[intent].append(BiLSTMCRF(vocab_size=len(separate_word_to_index[intent]), word_embedding_dim=50, hidden_dim=64, output_dim=len(separate_tag_to_index[intent])))\n",
    "    models[intent].append(optim.SGD(models[intent][0].parameters(), lr=0.01, weight_decay=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent: assignment operation\n",
      "Actual tags: tensor([2, 4, 3, 1])\n",
      "Predicted tags: [[0, 4, 4, 2]]\n",
      "Intent: git operation\n",
      "Actual tags: tensor([4])\n",
      "Predicted tags: [[2]]\n",
      "Intent: interactive commands\n",
      "Actual tags: tensor([1, 1, 1, 2])\n",
      "Predicted tags: [[2, 0, 0, 0]]\n",
      "Intent: bitwise operation\n",
      "Actual tags: tensor([3, 3, 3, 2, 5, 3, 3, 4, 1, 3, 4])\n",
      "Predicted tags: [[2, 5, 0, 4, 4, 1, 2, 5, 1, 1, 1]]\n",
      "Intent: for loop\n",
      "Actual tags: tensor([3, 3, 3, 3, 3, 3, 2, 3, 7, 3, 3, 6, 1])\n",
      "Predicted tags: [[7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]]\n",
      "Intent: ide operation\n",
      "Actual tags: tensor([6, 2, 4])\n",
      "Predicted tags: [[6, 0, 6]]\n",
      "Intent: comment\n",
      "Actual tags: tensor([3, 1, 1, 2])\n",
      "Predicted tags: [[3, 1, 0, 3]]\n",
      "Intent: constant declaration\n",
      "Actual tags: tensor([3, 3, 3, 3, 3, 4, 3, 3, 5])\n",
      "Predicted tags: [[4, 2, 6, 4, 2, 4, 5, 4, 2]]\n",
      "Intent: conditional operation\n",
      "Actual tags: tensor([4, 3, 6, 4, 1, 8, 4, 5, 7, 2, 4, 4, 4, 1, 4, 4, 4])\n",
      "Predicted tags: [[6, 4, 4, 2, 3, 6, 6, 8, 7, 4, 4, 4, 2, 3, 5, 8, 7]]\n",
      "Intent: assertion\n",
      "Actual tags: tensor([3, 4, 5, 7, 6, 1])\n",
      "Predicted tags: [[5, 4, 5, 5, 5, 5]]\n",
      "Intent: variable declaration\n",
      "Actual tags: tensor([3, 3, 6, 3, 3, 3, 4, 3, 3, 3, 3])\n",
      "Predicted tags: [[1, 6, 6, 6, 6, 1, 0, 1, 3, 3, 3]]\n",
      "Intent: function declaration\n",
      "Actual tags: tensor([3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 6, 5, 3, 3, 3])\n",
      "Predicted tags: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 4, 5, 3, 0, 0]]\n",
      "Intent: class declaration\n",
      "Actual tags: tensor([1, 2, 1, 1, 1])\n",
      "Predicted tags: [[1, 1, 1, 1, 1]]\n",
      "Intent: libraries\n",
      "Actual tags: tensor([1, 2])\n",
      "Predicted tags: [[2, 0]]\n",
      "Intent: while loop\n",
      "Actual tags: tensor([3, 3, 3, 3, 3, 3, 2, 4, 6, 6, 6, 6, 1])\n",
      "Predicted tags: [[3, 4, 0, 5, 2, 6, 1, 1, 6, 3, 3, 4, 3]]\n",
      "Intent: casting\n",
      "Actual tags: tensor([1, 1, 1, 4, 3, 1, 1, 2])\n",
      "Predicted tags: [[3, 1, 4, 1, 4, 1, 2, 2]]\n",
      "Intent: membership operation\n",
      "Actual tags: tensor([3, 1, 3, 6, 3, 3, 5])\n",
      "Predicted tags: [[7, 1, 7, 4, 1, 1, 7]]\n",
      "Intent: output\n",
      "Actual tags: tensor([2, 2, 2, 5])\n",
      "Predicted tags: [[6, 5, 6, 6]]\n",
      "Intent: array operation\n",
      "Actual tags: tensor([6, 6, 3, 6, 5, 2])\n",
      "Predicted tags: [[0, 3, 0, 3, 4, 0]]\n",
      "Intent: mathematical operation\n",
      "Actual tags: tensor([3, 6, 4, 6])\n",
      "Predicted tags: [[4, 1, 2, 6]]\n",
      "Intent: file system\n",
      "Actual tags: tensor([4, 2])\n",
      "Predicted tags: [[2, 2]]\n",
      "Intent: input\n",
      "Actual tags: tensor([2, 2, 2, 2, 2, 2, 4, 5, 5, 2, 2, 2, 2, 3, 1])\n",
      "Predicted tags: [[4, 3, 4, 5, 5, 5, 1, 0, 1, 5, 5, 5, 5, 5, 5]]\n"
     ]
    }
   ],
   "source": [
    "# Check predictions before training\n",
    "# tarining data {\n",
    "#     intent: [x_train, y_train, x_test, y_test]\n",
    "# }\n",
    "with torch.no_grad():\n",
    "    for intent in intents:\n",
    "        print(f'Intent: {intent}')\n",
    "        precheck_sent = prepare_sequence(training_data[intent][0][0].split(), separate_word_to_index[intent])\n",
    "        precheck_tag = prepare_sequence(training_data[intent][1][0], separate_tag_to_index[intent])\n",
    "        print(\"Actual tags:\", precheck_tag)\n",
    "        print(\"Predicted tags:\", models[intent][0](precheck_sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def train(model, optimizer, x_train, y_train,epochs=10):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        total_loss = 0\n",
    "        for sentence, tags in zip(x_train, y_train):\n",
    "            # Step 1. Remember that Pytorch accumulates gradients.\n",
    "            # We need to clear them out before each instance\n",
    "            model.zero_grad()\n",
    "        \n",
    "            sentence = prepare_sequence(sentence.split(), separate_word_to_index[intent])\n",
    "            target_tags = prepare_sequence(tags, separate_tag_to_index[intent])\n",
    "\n",
    "            # Step 3. Run our forward pass.\n",
    "            loss = model.neg_log_likelihood(sentence, target_tags)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch: {epoch}, Loss: {total_loss / len(x_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in intents:\n",
    "    print(f'Training model for intent: {intent}')\n",
    "    x_train, y_train = training_data[intent][0], training_data[intent][1]\n",
    "    train(models[intent][0], models[intent][1], x_train, y_train, epochs=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent: assignment operation\n",
      "Actual tags: tensor([2, 4, 3, 1])\n",
      "Predicted tags: [[2, 4, 3, 1]]\n",
      "Intent: git operation\n",
      "Actual tags: tensor([4])\n",
      "Predicted tags: [[4]]\n",
      "Intent: interactive commands\n",
      "Actual tags: tensor([1, 1, 1, 2])\n",
      "Predicted tags: [[1, 1, 1, 2]]\n",
      "Intent: bitwise operation\n",
      "Actual tags: tensor([3, 3, 3, 2, 5, 3, 3, 4, 1, 3, 4])\n",
      "Predicted tags: [[3, 3, 3, 2, 5, 3, 3, 4, 1, 3, 4]]\n",
      "Intent: for loop\n",
      "Actual tags: tensor([3, 3, 3, 3, 3, 3, 2, 3, 7, 3, 3, 6, 1])\n",
      "Predicted tags: [[3, 3, 3, 3, 3, 3, 2, 3, 7, 3, 3, 6, 1]]\n",
      "Intent: ide operation\n",
      "Actual tags: tensor([6, 2, 4])\n",
      "Predicted tags: [[6, 2, 4]]\n",
      "Intent: comment\n",
      "Actual tags: tensor([3, 1, 1, 2])\n",
      "Predicted tags: [[3, 1, 1, 2]]\n",
      "Intent: constant declaration\n",
      "Actual tags: tensor([3, 3, 3, 3, 3, 4, 3, 3, 5])\n",
      "Predicted tags: [[3, 3, 3, 3, 3, 4, 3, 3, 5]]\n",
      "Intent: conditional operation\n",
      "Actual tags: tensor([4, 3, 6, 4, 1, 8, 4, 5, 7, 2, 4, 4, 4, 1, 4, 4, 4])\n",
      "Predicted tags: [[4, 3, 6, 4, 1, 8, 4, 5, 7, 2, 4, 4, 4, 1, 4, 4, 4]]\n",
      "Intent: assertion\n",
      "Actual tags: tensor([3, 4, 5, 7, 6, 1])\n",
      "Predicted tags: [[3, 4, 5, 7, 6, 1]]\n",
      "Intent: variable declaration\n",
      "Actual tags: tensor([3, 3, 6, 3, 3, 3, 4, 3, 3, 3, 3])\n",
      "Predicted tags: [[3, 3, 6, 3, 3, 3, 4, 3, 3, 3, 3]]\n",
      "Intent: function declaration\n",
      "Actual tags: tensor([3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 6, 5, 3, 3, 3])\n",
      "Predicted tags: [[3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 6, 5, 3, 3, 3]]\n",
      "Intent: class declaration\n",
      "Actual tags: tensor([1, 2, 1, 1, 1])\n",
      "Predicted tags: [[1, 2, 1, 1, 1]]\n",
      "Intent: libraries\n",
      "Actual tags: tensor([1, 2])\n",
      "Predicted tags: [[1, 2]]\n",
      "Intent: while loop\n",
      "Actual tags: tensor([3, 3, 3, 3, 3, 3, 2, 4, 6, 6, 6, 6, 1])\n",
      "Predicted tags: [[3, 3, 3, 3, 3, 3, 2, 4, 6, 6, 6, 6, 1]]\n",
      "Intent: casting\n",
      "Actual tags: tensor([1, 1, 1, 4, 3, 1, 1, 2])\n",
      "Predicted tags: [[1, 1, 1, 4, 3, 1, 1, 2]]\n",
      "Intent: membership operation\n",
      "Actual tags: tensor([3, 1, 3, 6, 3, 3, 5])\n",
      "Predicted tags: [[3, 1, 3, 6, 3, 3, 5]]\n",
      "Intent: output\n",
      "Actual tags: tensor([2, 2, 2, 5])\n",
      "Predicted tags: [[2, 2, 2, 5]]\n",
      "Intent: array operation\n",
      "Actual tags: tensor([6, 6, 3, 6, 5, 2])\n",
      "Predicted tags: [[6, 6, 3, 6, 5, 2]]\n",
      "Intent: mathematical operation\n",
      "Actual tags: tensor([3, 6, 4, 6])\n",
      "Predicted tags: [[3, 6, 4, 6]]\n",
      "Intent: file system\n",
      "Actual tags: tensor([4, 2])\n",
      "Predicted tags: [[4, 2]]\n",
      "Intent: input\n",
      "Actual tags: tensor([2, 2, 2, 2, 2, 2, 4, 5, 5, 2, 2, 2, 2, 3, 1])\n",
      "Predicted tags: [[2, 2, 2, 2, 2, 2, 4, 5, 5, 2, 2, 2, 2, 3, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Check predictions before training\n",
    "# tarining data {\n",
    "#     intent: [x_train, y_train, x_test, y_test]\n",
    "# }\n",
    "with torch.no_grad():\n",
    "    for intent in intents:\n",
    "        print(f'Intent: {intent}')\n",
    "        precheck_sent = prepare_sequence(training_data[intent][0][0].split(), separate_word_to_index[intent])\n",
    "        precheck_tag = prepare_sequence(training_data[intent][1][0], separate_tag_to_index[intent])\n",
    "        print(\"Actual tags:\", precheck_tag)\n",
    "        print(\"Predicted tags:\", models[intent][0](precheck_sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_data):\n",
    "    model.eval()\n",
    "    predictions = [] # a dictionary to store the predictions for each intent\n",
    "    with torch.no_grad():\n",
    "        for sentence in test_data:\n",
    "            precheck_sent = prepare_sequence(sentence.split(), separate_word_to_index[intent])\n",
    "            predictions.append(model(precheck_sent)[0])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation \n",
    "def evaluate(y_true, y_pred):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_true_binarized = mlb.fit_transform(y_true)\n",
    "    y_pred_binarized = mlb.transform(y_pred)\n",
    "    \n",
    "    f1 = f1_score(y_true_binarized, y_pred_binarized, average='weighted')\n",
    "    precision = precision_score(y_true_binarized, y_pred_binarized, average='weighted')\n",
    "    recall = recall_score(y_true_binarized, y_pred_binarized, average='weighted')\n",
    "    accuracy = accuracy_score(y_true_binarized, y_pred_binarized)\n",
    "    \n",
    "    return f1, precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent: assignment operation\n",
      "F1 Score: 0.9529411764705882\n",
      "Precision: 0.9742647058823529\n",
      "Recall: 0.9411764705882353\n",
      "Accuracy: 0.875\n",
      "----------------------------------------------------------------------\n",
      "Intent: git operation\n",
      "F1 Score: 0.9751552795031057\n",
      "Precision: 1.0\n",
      "Recall: 0.9565217391304348\n",
      "Accuracy: 0.875\n",
      "----------------------------------------------------------------------\n",
      "Intent: interactive commands\n",
      "F1 Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "Accuracy: 1.0\n",
      "----------------------------------------------------------------------\n",
      "Intent: bitwise operation\n",
      "F1 Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "Accuracy: 1.0\n",
      "----------------------------------------------------------------------\n",
      "Intent: for loop\n",
      "F1 Score: 0.9918330308529946\n",
      "Precision: 0.9844827586206897\n",
      "Recall: 1.0\n",
      "Accuracy: 0.9166666666666666\n",
      "----------------------------------------------------------------------\n",
      "Intent: ide operation\n",
      "F1 Score: 0.9674215587044533\n",
      "Precision: 0.9636222910216719\n",
      "Recall: 0.9736842105263158\n",
      "Accuracy: 0.896551724137931\n",
      "----------------------------------------------------------------------\n",
      "Intent: comment\n",
      "F1 Score: 0.962962962962963\n",
      "Precision: 1.0\n",
      "Recall: 0.9333333333333333\n",
      "Accuracy: 0.8\n",
      "----------------------------------------------------------------------\n",
      "Intent: constant declaration\n",
      "F1 Score: 0.983349330408154\n",
      "Precision: 0.9901234567901235\n",
      "Recall: 0.9777777777777777\n",
      "Accuracy: 0.85\n",
      "----------------------------------------------------------------------\n",
      "Intent: conditional operation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:895: UserWarning: unknown class(es) ['B-VAR', 'I-VAR'] will be ignored\n",
      "  warnings.warn(\n",
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9563761620800771\n",
      "Precision: 0.9815873015873016\n",
      "Recall: 0.9428571428571428\n",
      "Accuracy: 0.625\n",
      "----------------------------------------------------------------------\n",
      "Intent: assertion\n",
      "F1 Score: 0.7246376811594203\n",
      "Precision: 0.8695652173913043\n",
      "Recall: 0.6956521739130435\n",
      "Accuracy: 0.0\n",
      "----------------------------------------------------------------------\n",
      "Intent: variable declaration\n",
      "F1 Score: 0.9820873205741627\n",
      "Precision: 1.0\n",
      "Recall: 0.9659090909090909\n",
      "Accuracy: 0.9166666666666666\n",
      "----------------------------------------------------------------------\n",
      "Intent: function declaration\n",
      "F1 Score: 0.9795150501672242\n",
      "Precision: 0.9821428571428571\n",
      "Recall: 0.9791666666666666\n",
      "Accuracy: 0.9166666666666666\n",
      "----------------------------------------------------------------------\n",
      "Intent: class declaration\n",
      "F1 Score: 0.8253968253968255\n",
      "Precision: 0.8888888888888888\n",
      "Recall: 0.7777777777777778\n",
      "Accuracy: 0.5\n",
      "----------------------------------------------------------------------\n",
      "Intent: libraries\n",
      "F1 Score: 0.9545454545454545\n",
      "Precision: 1.0\n",
      "Recall: 0.9166666666666666\n",
      "Accuracy: 0.8333333333333334\n",
      "----------------------------------------------------------------------\n",
      "Intent: while loop\n",
      "F1 Score: 0.9454545454545454\n",
      "Precision: 0.9583333333333334\n",
      "Recall: 0.9375\n",
      "Accuracy: 0.5\n",
      "----------------------------------------------------------------------\n",
      "Intent: casting\n",
      "F1 Score: 0.9808429118773946\n",
      "Precision: 1.0\n",
      "Recall: 0.9655172413793104\n",
      "Accuracy: 0.875\n",
      "----------------------------------------------------------------------\n",
      "Intent: membership operation\n",
      "F1 Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "Accuracy: 1.0\n",
      "----------------------------------------------------------------------\n",
      "Intent: output\n",
      "F1 Score: 0.9517241379310345\n",
      "Precision: 0.942528735632184\n",
      "Recall: 0.9655172413793104\n",
      "Accuracy: 0.8333333333333334\n",
      "----------------------------------------------------------------------\n",
      "Intent: array operation\n",
      "F1 Score: 0.9702819530405737\n",
      "Precision: 1.0\n",
      "Recall: 0.9482758620689655\n",
      "Accuracy: 0.8571428571428571\n",
      "----------------------------------------------------------------------\n",
      "Intent: mathematical operation\n",
      "F1 Score: 0.9904604659695468\n",
      "Precision: 0.9936708860759493\n",
      "Recall: 0.9873417721518988\n",
      "Accuracy: 0.918918918918919\n",
      "----------------------------------------------------------------------\n",
      "Intent: file system\n",
      "F1 Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "Accuracy: 1.0\n",
      "----------------------------------------------------------------------\n",
      "Intent: input\n",
      "F1 Score: 0.9391812865497077\n",
      "Precision: 1.0\n",
      "Recall: 0.8947368421052632\n",
      "Accuracy: 0.8\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for intent in intents:\n",
    "    print(f'Intent: {intent}')\n",
    "    x_test, y_test = training_data[intent][2], training_data[intent][3]\n",
    "    predictions = predict(models[intent][0], x_test)\n",
    "\n",
    "    mapped_predictions = [[separate_index_to_tag[intent][tag] for tag in tags] for tags in predictions]\n",
    "\n",
    "    f1, precision, recall, accuracy = evaluate(y_test, mapped_predictions)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 2, 2, 2]\n",
      "Actual tags: ['B-ACTION', 'O', 'O', 'B-FILE']\n",
      "Predicted tags: ['B-ACTION', 'O', 'O', 'O']\n",
      "F1 Score: 0.6607142857142856\n",
      "Precision: 0.765625\n",
      "Recall: 0.625\n",
      "Accuracy: 0.75\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "intent = 'file system'\n",
    "inp = 'create new file test'\n",
    "label = ['B-ACTION' ,'O', 'O', 'B-FILE']\n",
    "constant_model = models[intent][0]\n",
    "constant_model.eval()\n",
    "predictions = [] # a dictionary to store the predictions for each intent\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(inp.split(), separate_word_to_index[intent])\n",
    "    pred = constant_model(precheck_sent)[0]\n",
    "    print(pred)\n",
    "\n",
    "mapped_predictions = [separate_index_to_tag[intent][tag] for tag in pred]\n",
    "\n",
    "print(\"Actual tags:\", label)\n",
    "print(\"Predicted tags:\", mapped_predictions)\n",
    "\n",
    "f1, precision, recall, accuracy = evaluate(label, mapped_predictions)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: create a variable called ay khara and set it to yasmine ghanem\n",
      "Intent: variable declaration\n",
      "Actual tags: ['O', 'O', 'O', 'O', 'B-VAR', 'I-VAR', 'O', 'O', 'O', 'B-VAL', 'I-VAL']\n",
      "Predicted tags: ['B-VAL', 'I-VAL', 'B-VAR', 'I-VAR', 'B-TYPE', 'O', 'B-VAR', 'I-VAR', 'B-VAR', 'I-VAR', 'O', 'B-TYPE']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sentence: cast x to an int\n",
      "Intent: casting\n",
      "Actual tags: ['O', 'B-VAR', 'O', 'O', 'B-CAST_TYPE']\n",
      "Predicted tags: ['O', 'O', 'B-VAR', 'I-VAR', 'O']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sentence: import the pandas library\n",
      "Intent: libraries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:895: UserWarning: unknown class(es) ['B-TYPE'] will be ignored\n",
      "  warnings.warn(\n",
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:895: UserWarning: unknown class(es) ['I-VAR'] will be ignored\n",
      "  warnings.warn(\n",
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentence:\u001b[39m\u001b[38;5;124m\"\u001b[39m, example[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntent:\u001b[39m\u001b[38;5;124m\"\u001b[39m, example[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m---> 16\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m mapped_predictions \u001b[38;5;241m=\u001b[39m [[separate_index_to_tag[example[\u001b[38;5;241m2\u001b[39m]][tag] \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags] \u001b[38;5;28;01mfor\u001b[39;00m tags \u001b[38;5;129;01min\u001b[39;00m predictions]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual tags:\u001b[39m\u001b[38;5;124m\"\u001b[39m, example[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[31], line 7\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, test_data)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m test_data:\n\u001b[0;32m      6\u001b[0m         precheck_sent \u001b[38;5;241m=\u001b[39m prepare_sequence(sentence\u001b[38;5;241m.\u001b[39msplit(), separate_word_to_index[intent])\n\u001b[1;32m----> 7\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprecheck_sent\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32mc:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 38\u001b[0m, in \u001b[0;36mBiLSTMCRF.forward\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence):\n\u001b[1;32m---> 38\u001b[0m     lstm_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_lstm_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# emissions from the lstm layer\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     tag_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrf\u001b[38;5;241m.\u001b[39mdecode(lstm_features)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tag_sequence\n",
      "Cell \u001b[1;32mIn[18], line 26\u001b[0m, in \u001b[0;36mBiLSTMCRF.__get_lstm_features\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_lstm_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_hidden()\n\u001b[1;32m---> 26\u001b[0m     word_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mlen\u001b[39m(sentence), \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     27\u001b[0m     lstm_out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(word_embeddings, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden)\n\u001b[0;32m     28\u001b[0m     lstm_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_to_tag(lstm_out)\n",
      "File \u001b[1;32mc:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# Check predictions before training\n",
    "test_example_1 = (\"create a variable called ay khara and set it to yasmine ghanem\", [\"O\", \"O\", \"O\", \"O\", \"B-VAR\", \"I-VAR\", \"O\", \"O\", \"O\", \"B-VAL\", \"I-VAL\"], \"variable declaration\")\n",
    "test_example_2 = (\"cast x to an int\", [\"O\", \"B-VAR\", \"O\", \"O\", \"B-CAST_TYPE\"], \"casting\")\n",
    "test_example_3 = (\"import the pandas library\", [\"O\", \"O\", \"B-LIB_NAME\", \"O\"], \"libraries\")\n",
    "test_example_4 = ('write a new comment multiply the emissions and transitions', ['O', 'O', 'O', 'B-COMMENT', 'I-COMMENT', 'I-COMMENT', 'I-COMMENT', 'I-COMMENT' ], 'comment')\n",
    "test_example_5 = ('define a new class person', ['O', 'O', 'O', 'O', 'B-CLASS_NAME'], 'class declaration')\n",
    "test_example_6 = ('create a new function named add that takes parameters x and y', ['O', 'O', 'O', 'O', 'O', 'B-FUNC', 'O', 'O', 'O', 'B-PARAM', 'O', 'B-PARAM'], 'function declaration')\n",
    "test_example_7 = ('create a new function called add with parameters num1 and num2', ['O', 'O', 'O', 'O', 'O', 'B-FUNC', 'O', 'O', 'O', 'B-PARAM', 'O', 'B-PARAM'], 'function declaration')\n",
    "\n",
    "test_data = [test_example_1, test_example_2, test_example_3, test_example_4, test_example_5, test_example_6, test_example_7]\n",
    "\n",
    "for index, example in enumerate(test_data):\n",
    "    print(\"Sentence:\", example[0])\n",
    "    print(\"Intent:\", example[2])\n",
    "\n",
    "    predictions = predict(models[example[2]][0], [example[0]])\n",
    "\n",
    "    mapped_predictions = [[separate_index_to_tag[example[2]][tag] for tag in tags] for tags in predictions]\n",
    "\n",
    "    print(\"Actual tags:\", example[1])\n",
    "    print(\"Predicted tags:\", mapped_predictions[0])\n",
    "\n",
    "    evaluated = evaluate([example[1]], mapped_predictions)\n",
    "\n",
    "    print(\"----------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# predictions = predict(test_model, test_data)\n",
    "# labels = []\n",
    "# predicted_tags = []\n",
    "\n",
    "# for index, prediction in enumerate(predictions):\n",
    "#     print(\"Test Example:\", index)\n",
    "#     mapped_tags = [all_tags[tag] for tag in prediction]\n",
    "#     predicted_tags.append(mapped_tags)\n",
    "#     labels.append(test_data[index][1])\n",
    "#     print(\"Actual tags:\", test_data[index][1])\n",
    "#     print(\"Predicted tags:\", mapped_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models\n",
    "for intent in intents:\n",
    "    torch.save(models[intent][0].state_dict(), f\"../models/separate_ner_models/{intent}_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try separate data with the contsrained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
