{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from enum import Enum\n",
    "import time\n",
    "import pyautogui\n",
    "# !python -m pip install mediapipe opencv-python matplotlib pyautogui\n",
    "# !conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTTP = 'https://'\n",
    "IP_ADDRESS = '192.168.1.10'\n",
    "URL =  HTTP + IP_ADDRESS + ':4343/video'\n",
    "\n",
    "cap = cv2.VideoCapture(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "horeizontal_threshold = 7\n",
    "verticall_threshold =1 \n",
    "class directions(Enum):\n",
    "    LEFT = 1\n",
    "    RIGHT = 2\n",
    "    UP = 3\n",
    "    DOWN = 4\n",
    "    STRAIGHT = 0\n",
    "def neared_distance(point0,point1,point2,frame):\n",
    "    x_0 = int(point0.x * frame.shape[1])\n",
    "    y_0 = int(point0.y * frame.shape[0])\n",
    "    \n",
    "    x_1 = int(point1.x * frame.shape[1])\n",
    "    y_1 = int(point1.y * frame.shape[0])\n",
    "    \n",
    "    x_2 = int(point2.x * frame.shape[1])\n",
    "    y_2 = int(point2.y * frame.shape[0])\n",
    "    \n",
    "    # calc the distance between point 0 and point 1\n",
    "    distance_1 = ((x_0 - x_1)**2 + (y_0 - y_1)**2)**0.5\n",
    "    \n",
    "    # calc the distance between point 0 and point 2\n",
    "    distance_2 = ((x_0 - x_2)**2 + (y_0 - y_2)**2)**0.5\n",
    "    # print(distance_1,distance_2)\n",
    "    return distance_1,distance_2\n",
    "\n",
    "def vertical_decision(mid_point, top_most, bottom_most, frame):\n",
    "    distance_1,distance_2 = neared_distance(mid_point, top_most, bottom_most,frame)\n",
    "    print('vertical_destances: ',distance_1,distance_2)\n",
    "    if abs(distance_1 - distance_2) < verticall_threshold:\n",
    "        return directions.STRAIGHT\n",
    "    elif distance_1 < distance_2:\n",
    "        return directions.UP\n",
    "    else:\n",
    "        return directions.DOWN\n",
    "    \n",
    "def horizontal_desecion(mid_point, left_most, right_most,frame):\n",
    "    distance_1,distance_2 = neared_distance(mid_point, left_most, right_most,frame)\n",
    "    distance_2-=5\n",
    "    print('horizontal_distances: ',distance_1,distance_2)\n",
    "    if abs(distance_1 - distance_2) < horeizontal_threshold:\n",
    "        return directions.STRAIGHT\n",
    "    elif distance_1 < distance_2:\n",
    "        return directions.LEFT\n",
    "    else:\n",
    "        return directions.RIGHT\n",
    "\n",
    "def move_mouse(direction):\n",
    "    if(direction == directions.STRAIGHT):\n",
    "        return\n",
    "    current_x, current_y = pyautogui.position()\n",
    "    if direction == directions.LEFT:\n",
    "        current_x -= 5\n",
    "    elif direction == directions.RIGHT:\n",
    "        current_x += 5\n",
    "    elif direction == directions.UP:\n",
    "        current_y += 5\n",
    "    elif direction == directions.DOWN:\n",
    "        current_y -= 5\n",
    "    else:\n",
    "        print('mouse is in the same position')\n",
    "    pyautogui.moveTo(int(current_x), int(current_y))\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "left_eye_mid_index= 468\n",
    "left_eye_leftmost = 33\n",
    "left_eye_rightmost = 246\n",
    "\n",
    "right_eye_mid_index = 473\n",
    "right_eye_leftmost = 362\n",
    "right_eye_rightmost = 466\n",
    "\n",
    "left_eye_boundary = [33, 133, 173, 157, 158, 159, 160, 161, 246, 163, 144, 145, 153, 154, 155, 133]\n",
    "right_eye_boundary = [362, 263, 373, 380, 381, 382, 384, 385, 386, 387, 388, 466, 390, 373, 374, 380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "with mp_face_mesh.FaceMesh(max_num_faces=1,\n",
    "                           refine_landmarks=True,\n",
    "                           min_detection_confidence=0.5,\n",
    "                           min_tracking_confidence=0.5) as face_mesh:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            break\n",
    "        result = face_mesh.process(frame)\n",
    "        for face_landmarks in result.multi_face_landmarks:\n",
    "            right_mid_point = face_landmarks.landmark[right_eye_mid_index]\n",
    "            right_rightmost_point = face_landmarks.landmark[right_eye_rightmost]\n",
    "            right_leftmost_point = face_landmarks.landmark[right_eye_leftmost]\n",
    "            horeizontal_dirction = horizontal_desecion(right_mid_point, right_rightmost_point, right_leftmost_point, frame)\n",
    "            pt1=right_mid_point\n",
    "            x = int(pt1.x * frame.shape[1])\n",
    "            y = int(pt1.y * frame.shape[0])\n",
    "            cv2.circle(frame, (x,y), 2, (0,255,0), -1)\n",
    "            \n",
    "            pt1=right_rightmost_point\n",
    "            x = int(pt1.x * frame.shape[1])\n",
    "            y = int(pt1.y * frame.shape[0])\n",
    "            cv2.circle(frame, (x,y), 2, (0,255,0), -1)\n",
    "            \n",
    "            pt1=right_leftmost_point\n",
    "            x = int(pt1.x * frame.shape[1])\n",
    "            y = int(pt1.y * frame.shape[0])\n",
    "            cv2.circle(frame, (x,y), 2, (0,255,0), -1)            \n",
    "            # print(horeizontal_dirction)\n",
    "            \n",
    "            \n",
    "            left_mid_point = face_landmarks.landmark[left_eye_mid_index]\n",
    "            left_rightmost_point = face_landmarks.landmark[left_eye_rightmost]\n",
    "            left_leftmost_point = face_landmarks.landmark[left_eye_leftmost]\n",
    "            # vertical_direction = horizontal_desecion(left_mid_point, left_rightmost_point, left_leftmost_point, frame)\n",
    "            \n",
    "            pt1=left_rightmost_point\n",
    "            x = int(pt1.x * frame.shape[1])\n",
    "            y = int(pt1.y * frame.shape[0])\n",
    "            cv2.circle(frame, (x,y), 2, (0,255,0), -1)\n",
    "            \n",
    "            pt1=left_leftmost_point\n",
    "            x = int(pt1.x * frame.shape[1])\n",
    "            y = int(pt1.y * frame.shape[0])\n",
    "            cv2.circle(frame, (x,y), 2, (0,255,0), -1)     \n",
    "            # print(vertical_direction)\n",
    "\n",
    "            for i in range(0,468):\n",
    "                pt1 = face_landmarks.landmark[i]\n",
    "                x = int(pt1.x * frame.shape[1])\n",
    "                y = int(pt1.y * frame.shape[0])\n",
    "                # cv2.circle(frame, (x,y), 2, (0,255,0), -1)\n",
    "        cv2.imshow('frame', cv2.flip(frame,1))\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        # time.sleep(2)\n",
    "\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
