{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from Logistic_Regression import *\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "# LabelBinarizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing function\n",
    "    # Convert all to lowercase\n",
    "    # Remove punctuations\n",
    "    # Remove stopwords\n",
    "\n",
    "stop_words = {'a', 'the', 'is', 'it', 'to', 'of', 'in', 'for', 'on', 'with', 'as', 'at', 'by', 'from',\n",
    "                 'an', 'be', 'are', 'was', 'were', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she',\n",
    "                   'we', 'they', 'me', 'him', 'her', 'us', 'them', 'my', 'your', 'his', 'its', 'our', 'their',\n",
    "                     'mine', 'yours', 'his', 'hers', 'ours', 'theirs', 'what', 'which', 'who', 'whom', 'whose',\n",
    "                       'where', 'when', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other',\n",
    "                         'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'too', 'very'}\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    text = ' '.join(word for word in text.split())\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_intent_data(intent_data_path):\n",
    "\t# Load JSON file\n",
    "\twith open(intent_data_path, 'r') as file:\n",
    "\t\tdata = json.load(file)\n",
    "\t# Convert to DataFrame\n",
    "\trows = []\n",
    "\tfor intent, sentences in data.items():\n",
    "\t\tfor sentence in sentences:\n",
    "\t\t\trows.append({'intent': intent, 'sentence': sentence})\n",
    "\n",
    "\tdf = pd.DataFrame(rows)\n",
    "\n",
    "\t# Apply preprocessing\n",
    "\tdf['processed_sentence'] = df['sentence'].apply(preprocess_text)\n",
    "\n",
    "\t# Display the DataFrame\n",
    "\treturn df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>sentence</th>\n",
       "      <th>processed_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Variable Declaration</td>\n",
       "      <td>make start time as double and initialize 0.000123</td>\n",
       "      <td>make start time as double and initialize 0000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variable Declaration</td>\n",
       "      <td>declare min value as integer and value 131313</td>\n",
       "      <td>declare min value as integer and value 131313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Variable Declaration</td>\n",
       "      <td>define settings as boolean and value false</td>\n",
       "      <td>define settings as boolean and value false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Variable Declaration</td>\n",
       "      <td>define y as integer and assign to 12345</td>\n",
       "      <td>define y as integer and assign to 12345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Variable Declaration</td>\n",
       "      <td>initialize k as string and initialize it with ...</td>\n",
       "      <td>initialize k as string and initialize it with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>Mouse Click</td>\n",
       "      <td>click right</td>\n",
       "      <td>click right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>Mouse Click</td>\n",
       "      <td>left click the mouse</td>\n",
       "      <td>left click the mouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>Mouse Click</td>\n",
       "      <td>right click the mouse</td>\n",
       "      <td>right click the mouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>Mouse Click</td>\n",
       "      <td>click the mouse button</td>\n",
       "      <td>click the mouse button</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>Mouse Click</td>\n",
       "      <td>right click the mouse button</td>\n",
       "      <td>right click the mouse button</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2915 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    intent                                           sentence   \n",
       "0     Variable Declaration  make start time as double and initialize 0.000123  \\\n",
       "1     Variable Declaration      declare min value as integer and value 131313   \n",
       "2     Variable Declaration         define settings as boolean and value false   \n",
       "3     Variable Declaration            define y as integer and assign to 12345   \n",
       "4     Variable Declaration  initialize k as string and initialize it with ...   \n",
       "...                    ...                                                ...   \n",
       "2910           Mouse Click                                        click right   \n",
       "2911           Mouse Click                               left click the mouse   \n",
       "2912           Mouse Click                              right click the mouse   \n",
       "2913           Mouse Click                             click the mouse button   \n",
       "2914           Mouse Click                       right click the mouse button   \n",
       "\n",
       "                                     processed_sentence  \n",
       "0      make start time as double and initialize 0000123  \n",
       "1         declare min value as integer and value 131313  \n",
       "2            define settings as boolean and value false  \n",
       "3               define y as integer and assign to 12345  \n",
       "4     initialize k as string and initialize it with ...  \n",
       "...                                                 ...  \n",
       "2910                                        click right  \n",
       "2911                               left click the mouse  \n",
       "2912                              right click the mouse  \n",
       "2913                             click the mouse button  \n",
       "2914                       right click the mouse button  \n",
       "\n",
       "[2915 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_intent_data('../intent_detection_dataset/final_intents_dataset.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      "(2915, 15002)\n",
      "Shape of y:\n",
      "(2915,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract N-grams\n",
    "def extract_ngrams(text, n=3):\n",
    "    words = text.split()\n",
    "    ngrams = []\n",
    "    for i in range(1, n + 1):\n",
    "        ngrams += [' '.join(words[j:j+i]) for j in range(len(words) - i + 1)]\n",
    "    return ngrams\n",
    "\n",
    "# Compute term frequencies\n",
    "def compute_term_frequencies(corpus):\n",
    "    term_frequencies = defaultdict(Counter)\n",
    "    for idx, document in enumerate(corpus):\n",
    "        ngrams = extract_ngrams(document)\n",
    "        term_frequencies[idx] = Counter(ngrams)\n",
    "    return term_frequencies\n",
    "\n",
    "# Compute document frequencies\n",
    "def compute_document_frequencies(term_frequencies):\n",
    "    document_frequencies = Counter()\n",
    "    for tf in term_frequencies.values():\n",
    "        for term in tf.keys():\n",
    "            document_frequencies[term] += 1\n",
    "    return document_frequencies\n",
    "\n",
    "# Compute TF-IDF\n",
    "def compute_tfidf(corpus):\n",
    "    term_frequencies = compute_term_frequencies(corpus)\n",
    "    document_frequencies = compute_document_frequencies(term_frequencies)\n",
    "    N = len(corpus)\n",
    "    tfidf = defaultdict(dict)\n",
    "    for idx, tf in term_frequencies.items():\n",
    "        for term, count in tf.items():\n",
    "            tfidf[idx][term] = (count / len(tf)) * math.log(N / (document_frequencies[term] + 1))\n",
    "    return tfidf, document_frequencies\n",
    "\n",
    "# Create TF-IDF matrix\n",
    "def create_tfidf_matrix(tfidf, vocabulary):\n",
    "    num_docs = len(tfidf)\n",
    "    num_terms = len(vocabulary)\n",
    "    # Initialize the matrix with zeros\n",
    "    tfidf_matrix = np.zeros((num_docs, num_terms))\n",
    "    # Populate the matrix with TF-IDF scores\n",
    "    for doc_idx, term_scores in tfidf.items():\n",
    "        for term, score in term_scores.items():\n",
    "            term_idx = vocabulary.get(term)\n",
    "            if term_idx is not None:\n",
    "                tfidf_matrix[doc_idx, term_idx] = score\n",
    "    return tfidf_matrix\n",
    "\n",
    "# Prepare corpus\n",
    "corpus = df['processed_sentence'].tolist()\n",
    "# print(corpus)\n",
    "\n",
    "# Compute TF-IDF scores\n",
    "tfidf, document_frequencies  = compute_tfidf(corpus)\n",
    "# print(tfidf[0])\n",
    "# print(document_frequencies)\n",
    "\n",
    "# Create vocabulary from all N-grams\n",
    "all_ngrams = set()\n",
    "for tf in tfidf.values():\n",
    "    all_ngrams.update(tf.keys())\n",
    "\n",
    "vocabulary = {term: idx for idx, term in enumerate(all_ngrams)}\n",
    "\n",
    "# Create TF-IDF matrix\n",
    "X = create_tfidf_matrix(tfidf, vocabulary)\n",
    "y = df['intent']\n",
    "\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(X.shape)\n",
    "print(\"Shape of y:\")\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2332, 15002)\n",
      "(2332,)\n",
      "(583, 15002)\n",
      "(583,)\n"
     ]
    }
   ],
   "source": [
    "# Encode labels = 24\n",
    "labels = df['intent'].unique()\n",
    "# print(labels.shape)\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
    "y = np.array([label_to_index[label] for label in y])\n",
    "# for i in range(len(y)):\n",
    "# \tprint(y[i])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict intent of custom input\n",
    "def predict_intent(custom_sentence, model):\n",
    "    # Preprocess the custom input\n",
    "    processed_sentence = preprocess_text(custom_sentence)\n",
    "    # Convert to N-gram TF-IDF features\n",
    "    ngrams = extract_ngrams(processed_sentence)\n",
    "    custom_tfidf = np.zeros(len(vocabulary))\n",
    "    term_counts = Counter(ngrams)\n",
    "    N = len(corpus) + 1\n",
    "    for term, count in term_counts.items():\n",
    "        if term in vocabulary:\n",
    "            term_idx = vocabulary[term]\n",
    "            tf = count / len(ngrams)\n",
    "            idf = math.log(N / (1 + document_frequencies.get(term, 0)))\n",
    "            custom_tfidf[term_idx] = tf * idf\n",
    "    # Predict the intent\n",
    "    predicted_intent_idx = model.predict(np.array([custom_tfidf]))[0]\n",
    "    predicted_intent = index_to_label[predicted_intent_idx]\n",
    "    return predicted_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9407665505226481\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train a classifier (Logistic Regression)\n",
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = lg_model.predict(X_test)\n",
    "\n",
    "# Map index to label\n",
    "y_test_labels = [index_to_label[idx] for idx in y_test]\n",
    "y_pred_labels = [index_to_label[idx] for idx in y_pred]\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test_labels, y_pred_labels))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test_labels, y_pred_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted intent for 'i want a method named ADD ':\n",
      " Function Declaration\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Test the model with custom input\n",
    "custom_sentence = \"i want a method named ADD \"\n",
    "predicted_intent = predict_intent(custom_sentence, lg_model)\n",
    "print(f\"Predicted intent for '{custom_sentence}':\\n {predicted_intent}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9742710120068611\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "class MulticlassLogisticRegression:\n",
    "    def __init__(self, lr: float, epochs: int, probability_threshold: float = 0.5, random_state=None):\n",
    "        self.lr = lr  # The learning rate\n",
    "        self.epochs = epochs  # The number of training epochs\n",
    "        self.probability_threshold = probability_threshold  # Threshold for classification\n",
    "        self.random_state = random_state  # Seed for reproducibility\n",
    "        self.weights = []  # Store weights for each class\n",
    "\n",
    "    def _prepare_input(self, X):\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.array(X)\n",
    "        # Add a new input with value 1 to each example (bias term)\n",
    "        ones = np.ones((X.shape[0], 1), dtype=X.dtype)\n",
    "        return np.concatenate((ones, X), axis=1)\n",
    "\n",
    "    def _initialize(self, num_weights: int, stdev: float = 0.01):\n",
    "        # Initialize the weights using a normally distributed random variable with a small standard deviation\n",
    "        np.random.seed(self.random_state)\n",
    "        return np.random.randn(num_weights) * stdev\n",
    "\n",
    "    def _gradient(self, X, y, weights):\n",
    "        # Compute and return the gradient of the weights with respect to the loss given X and y\n",
    "        error = y - sigmoid(np.dot(X, weights))\n",
    "        weight_gradient = np.dot(-X.T, error)\n",
    "        return weight_gradient\n",
    "\n",
    "    def _update(self, X, y, weights):\n",
    "        # Apply a single iteration on the weights\n",
    "        gradient = self._gradient(X, y, weights)\n",
    "        weights -= self.lr * gradient\n",
    "        return weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = self._prepare_input(X)\n",
    "        encoder = LabelBinarizer()\n",
    "        y_oh = encoder.fit_transform(y)\n",
    "\n",
    "        for i in range(y_oh.shape[1]):\n",
    "            weights = self._initialize(X.shape[1])\n",
    "            for _ in range(self.epochs):\n",
    "                weights = self._update(X, y_oh[:, i], weights)\n",
    "            self.weights.append(weights)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = self._prepare_input(X)\n",
    "        probas = []\n",
    "        for weights in self.weights:\n",
    "            proba = sigmoid(np.dot(X, weights))\n",
    "            probas.append(proba)\n",
    "        return np.array(probas).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        probas = self.predict_proba(X)\n",
    "        return np.argmax(probas, axis=1)\n",
    "    \n",
    "\n",
    "model = MulticlassLogisticRegression(lr=0.1, epochs=500, probability_threshold=0.5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "import pickle\n",
    "with open('logisticRegressionModel2.pkl', 'wb') as file:\n",
    "\tpickle.dump(model, file)\n",
    "\n",
    "#Load the model\n",
    "# with open('logisticRegressionModel.pkl', 'rb') as file:\n",
    "# \tmodel1 = pickle.load(file)\n",
    "#Load the model\n",
    "with open('logisticRegressionModel2.pkl', 'rb') as file:\n",
    "\tmodel2 = pickle.load(file)\n",
    "\n",
    "# function save the model\n",
    "def save_model(model, model_path):\n",
    "\twith open(model_path, 'wb') as file:\n",
    "\t\tpickle.dump(model, file)\n",
    "\n",
    "# function load the model\n",
    "def load_model(model_path):\n",
    "\twith open(model_path, 'rb') as file:\n",
    "\t\tmodel = pickle.load(file)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        48\n",
      "           1       1.00      1.00      1.00        46\n",
      "           2       1.00      1.00      1.00        23\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      0.83      0.91        12\n",
      "           5       0.95      1.00      0.97        36\n",
      "           6       0.95      1.00      0.98        21\n",
      "           7       0.92      1.00      0.96        12\n",
      "           8       1.00      0.95      0.98        22\n",
      "           9       1.00      0.95      0.97        20\n",
      "          10       0.95      1.00      0.97        77\n",
      "          11       1.00      1.00      1.00        33\n",
      "          12       0.94      1.00      0.97        15\n",
      "          13       1.00      1.00      1.00        11\n",
      "          14       1.00      1.00      1.00        17\n",
      "          15       1.00      0.50      0.67         6\n",
      "          16       1.00      0.75      0.86         4\n",
      "          17       0.96      0.92      0.94        25\n",
      "          18       0.98      1.00      0.99        53\n",
      "          19       1.00      0.91      0.95        11\n",
      "          20       1.00      1.00      1.00         7\n",
      "          21       1.00      1.00      1.00         6\n",
      "          22       1.00      1.00      1.00        44\n",
      "          23       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.98       574\n",
      "   macro avg       0.99      0.95      0.96       574\n",
      "weighted avg       0.98      0.98      0.98       574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classRep = classification_report(y_test,y_pred)\n",
    "print(classRep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted intent: Mathematical Operation\n",
      "\n",
      "Predicted intent: Mathematical Operation\n",
      "\n",
      "Predicted intent: Mathematical Operation\n",
      "\n",
      "Predicted intent: Assignment Operation\n",
      "\n",
      "Predicted intent: Assignment Operation\n",
      "\n",
      "Predicted intent: Conditional Statement\n",
      "\n",
      "Predicted intent: Assignment Operation\n",
      "\n",
      "Predicted intent: Output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assignment = [\"assign x to y\",\n",
    "    \"set the value of name to yasmine\",\n",
    "    \"assign yasmine to name\",\n",
    "    \"x equals y\",\n",
    "    \"number is equal to 50\",\n",
    "    \"max is equal 323.88\",\n",
    "    \"assign max value to current value\",\n",
    "    \"update max value with value\"]\n",
    "# Test the model with custom input\n",
    "# custom_sentence = \"create a file named 'test.txt'\"\n",
    "for sent in assignment:\n",
    "\tpredicted_intent = predict_intent(sent, model2)\n",
    "\tprint(f\"Predicted intent: {predicted_intent}\\n\")\n",
    "\n",
    "ide = [\"select lines 1 through 5\",\n",
    "    \"select line 9\",\n",
    "    \"highlight from line 3 to line 7\",\n",
    "    \"go to line 10\",\n",
    "    \"delete line 6\",\n",
    "    \"delete lines 2 through 4\",\n",
    "    \"focus terminal\",\n",
    "    \"kill terminal\",\n",
    "    \"open terminal\",\n",
    "    \"new terminal\",\n",
    "    \"undo\",\n",
    "    \"redo\",\n",
    "    \"copy\",\n",
    "    \"paste\"]\n",
    "# for sent in ide:\n",
    "# \tpredicted_intent = predict_intent(sent, model2)\n",
    "# \tprint(f\"Predicted intent for ide:\\n {predicted_intent}\")\n",
    "# predicted_intent = predict_intent(custom_sentence, model2)\n",
    "# print(f\"Predicted intent for '{custom_sentence}':\\n {predicted_intent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted intent: Function Declaration\n",
      "\n",
      "Predicted intent: Function Declaration\n",
      "\n",
      "Predicted intent: Variable Declaration\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test =[\n",
    "    \"i want a method named ADD \",\n",
    "\t\"Declare function with name SUB \",\n",
    "\t\"Declare variable and assign it to 3\"\n",
    "]\n",
    "for sent in test:\n",
    "\tpredicted_intent = predict_intent(sent, model2)\n",
    "\tprint(f\"Predicted intent: {predicted_intent}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robinenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
