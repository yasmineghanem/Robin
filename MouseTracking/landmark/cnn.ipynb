{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\__init__.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Paths to the CSV files\n",
    "train_path = './training.csv'\n",
    "test_path = './test.csv'\n",
    "lookid_path = './IdLookupTable.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n",
    "lookid_data = pd.read_csv(lookid_path)\n",
    "\n",
    "# Columns for Y_train\n",
    "y_columns = [\n",
    "    'nose_tip_x', 'nose_tip_y',\n",
    "    'mouth_left_corner_x', 'mouth_left_corner_y',\n",
    "    'mouth_right_corner_x', 'mouth_right_corner_y',\n",
    "    'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
    "    'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y'\n",
    "]\n",
    "\n",
    "# Select the Image column for X_train\n",
    "X_train = train_data['Image']\n",
    "\n",
    "# Select the specified columns for Y_train\n",
    "Y_train = train_data[y_columns]\n",
    "\n",
    "# Concatenate X_train and Y_train to discard rows with missing values\n",
    "combined_data = pd.concat([X_train, Y_train], axis=1)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "combined_data = combined_data.dropna()\n",
    "\n",
    "# Split the combined data back into X_train and Y_train\n",
    "X_train = combined_data['Image']\n",
    "Y_train = combined_data[y_columns]\n",
    "\n",
    "# Convert X_train to numpy array and reshape\n",
    "X_train = np.array([np.fromstring(image, sep=' ').reshape(96, 96, 1) for image in X_train])\n",
    "X_train = X_train.astype('float32') / 255.0  # Normalize pixel values\n",
    "\n",
    "# Convert Y_train to numpy array\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(96, 96, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(30, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "# Save the model\n",
    "# model.save('path/to/your/model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to the CSV files\n",
    "train_path = './train.csv'\n",
    "test_path = './test.csv'\n",
    "# lookid_path = './IdLookupTable.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n",
    "# lookid_data = pd.read_csv(lookid_path)\n",
    "\n",
    "# Columns for Y_train\n",
    "y_columns = [\n",
    "    'left_eye_center_x','left_eye_center_y',\n",
    "    'right_eye_center_x','right_eye_center_y',\n",
    "    'nose_tip_x', 'nose_tip_y',\n",
    "    'mouth_left_corner_x', 'mouth_left_corner_y',\n",
    "    'mouth_right_corner_x', 'mouth_right_corner_y',\n",
    "    'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
    "    'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y'\n",
    "]\n",
    "\n",
    "# Select the Image column for X_train\n",
    "X_train = train_data['Image']\n",
    "\n",
    "# Select the specified columns for Y_train\n",
    "Y_train = train_data[y_columns]\n",
    "\n",
    "# Concatenate X_train and Y_train to find rows with missing values\n",
    "combined_data = pd.concat([X_train, Y_train], axis=1)\n",
    "\n",
    "# Find rows with any missing values\n",
    "missing_data = combined_data[combined_data.isnull().any(axis=1)]\n",
    "non_missing_data = combined_data.dropna()\n",
    "\n",
    "# Split the combined data back into X_train and Y_train\n",
    "X_train_non_missing = non_missing_data['Image']\n",
    "Y_train_non_missing = non_missing_data[y_columns]\n",
    "\n",
    "# Convert X_train to numpy array and reshape\n",
    "X_train_non_missing = np.array([np.fromstring(image, sep=' ').reshape(96, 96, 1) for image in X_train_non_missing])\n",
    "X_train_non_missing = X_train_non_missing.astype('float32') / 255.0  # Normalize pixel values\n",
    "\n",
    "# Convert Y_train to numpy array\n",
    "Y_train_non_missing = np.array(Y_train_non_missing)\n",
    "\n",
    "# Mediapipe setup\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Function to detect face landmarks\n",
    "def detect_face_landmarks(image):\n",
    "    results = face_mesh.process(image)\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "        return landmarks\n",
    "    return None\n",
    "\n",
    "# Process images with missing data\n",
    "for idx, row in missing_data.iterrows():\n",
    "    image = np.fromstring(row['Image'], sep=' ').reshape(96, 96)\n",
    "    image_rgb = cv2.cvtColor(image.astype('uint8'), cv2.COLOR_GRAY2RGB)\n",
    "# keypoint_indices = [4, 61, 291, 0, 17]  # Indices of the keypoints to extract\n",
    "\n",
    "    landmarks = detect_face_landmarks(image_rgb)\n",
    "    if landmarks:\n",
    "        # Example to fill nose_tip_x and nose_tip_y\n",
    "        row['nose_tip_x'] = landmarks[4].x * 96\n",
    "        row['nose_tip_y'] = landmarks[4].y * 96\n",
    "        row['mouth_left_corner_x'] = landmarks[61].x * 96\n",
    "        row['mouth_left_corner_y'] = landmarks[61].y * 96\n",
    "        row['mouth_right_corner_x'] = landmarks[291].x * 96\n",
    "        row['mouth_right_corner_y'] = landmarks[291].y * 96\n",
    "        row['mouth_center_top_lip_x'] = landmarks[0].x * 96\n",
    "        row['mouth_center_top_lip_y'] = landmarks[0].y * 96\n",
    "        row['mouth_center_bottom_lip_x'] = landmarks[17].x * 96\n",
    "        row['mouth_center_bottom_lip_y'] = landmarks[17].y * 96\n",
    "        row['left_eye_center_x']= landmarks[263].x * 96\n",
    "        row['left_eye_center_y'] = landmarks[263].x * 96\n",
    "        row['right_eye_center_x']= landmarks[33].x * 96\n",
    "        row['right_eye_center_y']= landmarks[33].x * 96\n",
    "        \n",
    "        # Add more points as needed\n",
    "        combined_data.loc[idx] = row\n",
    "\n",
    "# Drop rows still having any missing values\n",
    "combined_data = combined_data.dropna()\n",
    "\n",
    "# Split the combined data back into X_train and Y_train\n",
    "X_train = combined_data['Image']\n",
    "Y_train = combined_data[y_columns]\n",
    "\n",
    "# Convert X_train to numpy array and reshape\n",
    "X_train = np.array([np.fromstring(image, sep=' ').reshape(96, 96, 1) for image in X_train])\n",
    "X_train = X_train.astype('float32') / 255.0  # Normalize pixel values\n",
    "\n",
    "# Convert Y_train to numpy array\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(len(Y_train))\n",
    "\n",
    "# Show one of the images with landmarks\n",
    "def show_image_with_landmarks(image, landmarks):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    for landmark in landmarks:\n",
    "        plt.scatter(landmark.x * image.shape[1], landmark.y * image.shape[0], s=10, c='red')\n",
    "    plt.show()\n",
    "\n",
    "# Display an example\n",
    "example_idx = missing_data.index[0]\n",
    "example_image = np.fromstring(missing_data.loc[example_idx, 'Image'], sep=' ').reshape(96, 96)\n",
    "example_image_rgb = cv2.cvtColor(example_image.astype('uint8'), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "example_landmarks = detect_face_landmarks(example_image_rgb)\n",
    "if example_landmarks:\n",
    "    show_image_with_landmarks(example_image, example_landmarks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, Y_train, epochs=350, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Process test data\n",
    "test_images = np.array([np.fromstring(image, sep=' ').reshape(96, 96, 1) for image in test_data['Image']])\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Predict key points on test data\n",
    "predicted_points = model.predict(test_images)\n",
    "\n",
    "# Function to plot image with key points\n",
    "def plot_image_with_keypoints(image, keypoints):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    keypoints = keypoints.reshape(-1, 2)\n",
    "    for (x, y) in keypoints:\n",
    "        plt.plot(x, y, 'ro')\n",
    "    plt.show()\n",
    "\n",
    "# Plot some random test images with predicted key points\n",
    "num_images_to_show = 5\n",
    "random_indices = random.sample(range(len(test_images)), num_images_to_show)\n",
    "\n",
    "for i in random_indices:\n",
    "    plot_image_with_keypoints(test_images[i].reshape(96, 96), predicted_points[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
