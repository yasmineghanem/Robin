{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12ebadb1ab0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# from bilstm_crf import BiLSTMCRF\n",
    "from torch import optim\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import torch.nn as nn\n",
    "from TorchCRF import CRF\n",
    "\n",
    "# import evaluation metrics \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BiLSTMCRF(nn.Module):\n",
    "    def __init__(self, vocab_size, word_embedding_dim, intent_embedding_dim, hidden_dim, output_dim, number_of_intents):\n",
    "        \n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "        # hyperparameters\n",
    "        self.word_embedding_dim = word_embedding_dim\n",
    "        self.inten_embedding_dim = intent_embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # model layers\n",
    "        self.word_embedding = nn.Embedding(vocab_size, word_embedding_dim)\n",
    "        self.intent_embedding = nn.Embedding(number_of_intents, intent_embedding_dim)\n",
    "        self.lstm = nn.LSTM(word_embedding_dim + intent_embedding_dim, hidden_dim // 2, bidirectional=True, dropout=0.2)\n",
    "        self.hidden_to_tag = nn.Linear(hidden_dim, output_dim)\n",
    "        self.crf = CRF(output_dim)\n",
    "\n",
    "    def __init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2), torch.randn(2, 1, self.hidden_dim // 2)) # initialize hidden state\n",
    "\n",
    "    def __get_lstm_features(self, sentence, intent):\n",
    "        self.hidden = self.__init_hidden()\n",
    "        word_embeddings = self.word_embedding(sentence).view(len(sentence), 1, -1)\n",
    "        # print(\"Word Embedding Shape:\", word_embeddings.shape) # (len(sentence), batch_size, embedding_dimension)\n",
    "        intent_embeddings = self.intent_embedding(intent).view(1, 1, -1).repeat(len(sentence), 1, 1)\n",
    "        # print(\"Intent Embedding Shape:\", intent_embeddings.shape) # (len(sentence), batch_size, embedding_dimension)\n",
    "        embeddings = torch.cat((word_embeddings, intent_embeddings), dim=2) \n",
    "        # print(\"Embedding Shape:\", embeddings.shape) # (len(sentence), batch_size, embedding_dimension * 2)\n",
    "        lstm_out, self.hidden = self.lstm(embeddings, self.hidden)\n",
    "        # print(\"LSTM Out Shape:\", lstm_out.shape) # (len(sentence), batch_size, hidden_dimension)\n",
    "        lstm_features = self.hidden_to_tag(lstm_out)\n",
    "        # print(\"LSTM Features Shape:\", lstm_features.shape) # (len(sentence), batch_size, output_dimension (number of target entities)) -> number of entities 3andena 30 \n",
    "        return lstm_features\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags, intent, mask):\n",
    "        # print(\"Intent Shape:\", intent.shape)\n",
    "        features = self.__get_lstm_features(sentence, intent) # emissions from the lstm layer\n",
    "        # print(\"Features Shape:\", features.shape)\n",
    "        # print(\"NEG LIKE FEATURES:\", features.shape)\n",
    "        # print(features)\n",
    "        # mask = mask.view(1, -1)\n",
    "        # print(\"Mask Shape:\", mask.shape)\n",
    "        # repeated_mask = mask.repeat(features.shape[0], 1, 1).contiguous()\n",
    "        # print(repeated_mask.shape)\n",
    "        # print(repeated_mask)\n",
    "        # features = features * mask\n",
    "        # print(\"Intent:\", intent[0])\n",
    "        # print(\"Mask:\", mask)\n",
    "        # print(\"Features:\", features)\n",
    "        # print(\"Features Shape:\", features.shape)\n",
    "        # features = features * mask\n",
    "        tags = tags.view(-1, 1)\n",
    "        loss = -self.crf(features, tags)\n",
    "        # print(loss)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, sentence, intent, mask):\n",
    "        lstm_features = self.__get_lstm_features(sentence, intent) # emissions from the lstm layer\n",
    "        # print(\"LSTM Features\", lstm_features)\n",
    "        # print(\"Forward LSTM features:\", lstm_features.shape)\n",
    "        # repeated_mask = mask.repeat(lstm_features.shape[0], 1, 1).contiguous()\n",
    "        # test_mask = torch.ones(len(sentence), 1, self.output_dim)\n",
    "        # print(\"Repeated Mask Shape:\", repeated_mask.shape)\n",
    "        # print(\"Mask Shape:\", mask.shape)\n",
    "        # lstm_features = lstm_features * mask\n",
    "        # print(\"Forward LSTM features:\", lstm_features.shape)\n",
    "        tag_sequence = self.crf.decode(lstm_features)\n",
    "        # print(\"Tag Sequence:\", tag_sequence)\n",
    "        return tag_sequence\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HELPER FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "WORD_EMBEDDING_DIM = 50\n",
    "INTENT_EMBEDIING_DIM = 50\n",
    "HIDDEN_DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    data = pd.read_csv('../ner_dataset/ner_dataset.csv', encoding='latin1')\n",
    "\n",
    "    # remove white spaces from column names\n",
    "    data.columns = data.columns.str.strip()\n",
    "\n",
    "    print(data.columns)\n",
    "    # Group by 'Sentence #' and aggregate\n",
    "    grouped_data = data.groupby('Sentence #').agg({\n",
    "        'Word': lambda x: ''.join(x),  # Join words into a single sentence\n",
    "        'Tag': lambda x: list(x.str.strip()),       # Collect tags into a list\n",
    "        'Intent': lambda x: list(x.str.strip().str.replace('_', ' '))     # Collect intents into a list\n",
    "    }).reset_index()  # Reset index to make 'Sentence #' a regular column\n",
    "\n",
    "    return data, grouped_data\n",
    "\n",
    "\n",
    "def prepare_data(dataframe):\n",
    "    dataset = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        sentence = row['Word'][1:]\n",
    "        tags = row['Tag']\n",
    "        intents = row['Intent']\n",
    "        dataset.append((sentence, tags, intents[0]))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sentence #', 'Word', 'Tag', 'Intent'], dtype='object')\n",
      "[' variable declaration' ' function declaration' ' class declaration'\n",
      " ' assignment operation' ' array operation' ' bitwise operation'\n",
      " ' mathematical operation' ' membership operation' ' casting'\n",
      " ' io operation' ' assertion' ' libraries' ' file system' ' ide operation'\n",
      " ' comment' ' conditional operation' ' iterative operation']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>make start time as double and initialize 0.00...</td>\n",
       "      <td>[O, B-VAR, I-VAR, O, B-TYPE, O, O, B-VAL]</td>\n",
       "      <td>[variable declaration, variable declaration, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>declare min value as integer and value 131313</td>\n",
       "      <td>[O, B-VAR, I-VAR, O, B-TYPE, O, O, B-VAL]</td>\n",
       "      <td>[variable declaration, variable declaration, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>define settings as boolean and value false</td>\n",
       "      <td>[O, B-VAR, O, B-TYPE, O, O, B-VAL]</td>\n",
       "      <td>[variable declaration, variable declaration, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>define y as integer and assign to 12345</td>\n",
       "      <td>[O, B-VAR, O, B-TYPE, O, O, O, B-VAL]</td>\n",
       "      <td>[variable declaration, variable declaration, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>initialize k as string and initialize it with...</td>\n",
       "      <td>[O, B-VAR, O, B-TYPE, O, O, O, O, B-VAL, I-VAL]</td>\n",
       "      <td>[variable declaration, variable declaration, v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence #                                               Word   \n",
       "0           0   make start time as double and initialize 0.00...  \\\n",
       "1           1      declare min value as integer and value 131313   \n",
       "2           2         define settings as boolean and value false   \n",
       "3           3            define y as integer and assign to 12345   \n",
       "4           4   initialize k as string and initialize it with...   \n",
       "\n",
       "                                               Tag   \n",
       "0        [O, B-VAR, I-VAR, O, B-TYPE, O, O, B-VAL]  \\\n",
       "1        [O, B-VAR, I-VAR, O, B-TYPE, O, O, B-VAL]   \n",
       "2               [O, B-VAR, O, B-TYPE, O, O, B-VAL]   \n",
       "3            [O, B-VAR, O, B-TYPE, O, O, O, B-VAL]   \n",
       "4  [O, B-VAR, O, B-TYPE, O, O, O, O, B-VAL, I-VAL]   \n",
       "\n",
       "                                              Intent  \n",
       "0  [variable declaration, variable declaration, v...  \n",
       "1  [variable declaration, variable declaration, v...  \n",
       "2  [variable declaration, variable declaration, v...  \n",
       "3  [variable declaration, variable declaration, v...  \n",
       "4  [variable declaration, variable declaration, v...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format data\n",
    "data, goruped_data = read_dataset()\n",
    "print(data[\"Intent\"].unique())\n",
    "\n",
    "goruped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('make start time as double and initialize 0.000123', ['O', 'B-VAR', 'I-VAR', 'O', 'B-TYPE', 'O', 'O', 'B-VAL'], 'variable declaration')\n"
     ]
    }
   ],
   "source": [
    "training_data = prepare_data(goruped_data)\n",
    "\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PREPARE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['variable declaration', 'function declaration', 'class declaration', 'assignment operation', 'array operation', 'bitwise operation', 'mathematical operation', 'membership operation', 'casting', 'io operation', 'assertion', 'libraries', 'file system', 'ide operation', 'comment', 'conditional operation', 'iterative operation']\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# convert intent to index\n",
    "with open('../ner_dataset/annotations/annotations.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "annotations = data['annotations']\n",
    "\n",
    "intents = list(annotations.keys())\n",
    "\n",
    "print(intents)\n",
    "print(len(intents))\n",
    "\n",
    "intent_to_index = {intent: index for index, intent in enumerate(intents)}\n",
    "\n",
    "intent_to_index[\"<UNK>\"] = len(intent_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-VAR': 1,\n",
       " 'I-VAR': 2,\n",
       " 'B-TYPE': 3,\n",
       " 'B-VAL': 4,\n",
       " 'I-VAL': 5,\n",
       " 'B-FUNC': 6,\n",
       " 'I-FUNC': 7,\n",
       " 'B-PARAM': 8,\n",
       " 'I-PARAM': 9,\n",
       " 'B-CLASS_NAME': 10,\n",
       " 'I-CLASS_NAME': 11,\n",
       " 'B-LHS': 12,\n",
       " 'I-LHS': 13,\n",
       " 'B-RHS': 14,\n",
       " 'I-RHS': 15,\n",
       " 'B-OPERATION': 16,\n",
       " 'B-ELEMENT': 17,\n",
       " 'I-ARRAY': 18,\n",
       " 'B-ARRAY': 19,\n",
       " 'I-ELEMENT': 20,\n",
       " 'I-OPERATION': 21,\n",
       " 'B-OPERATOR': 22,\n",
       " 'B-OPERAND': 23,\n",
       " 'I-OPERAND': 24,\n",
       " 'I-OPERATOR': 25,\n",
       " 'B-CONDITION': 26,\n",
       " 'B-COLLECTION': 27,\n",
       " 'I-COLLECTION': 28,\n",
       " 'I-CONDITION': 29,\n",
       " 'B-CAST_TYPE': 30,\n",
       " 'B-INPUT': 31,\n",
       " 'B-OUTPUT': 32,\n",
       " 'B-LIB_NAME': 33,\n",
       " 'B-ACTION': 34,\n",
       " 'I-ACTION': 35,\n",
       " 'B-DIR': 36,\n",
       " 'B-LINE': 37,\n",
       " 'B-FILE': 38,\n",
       " 'I-COMMENT': 39,\n",
       " 'B-COMMENT': 40,\n",
       " 'B-LOG': 41,\n",
       " 'B-LOOP': 42,\n",
       " 'B-STEP': 43,\n",
       " 'B-END': 44,\n",
       " 'B-START': 45,\n",
       " '<UNK>': 46}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert data to indices\n",
    "word_to_index = {}\n",
    "tag_to_index = {}\n",
    "for sentence, tags, intents in training_data:\n",
    "    for word in sentence.split():\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = len(word_to_index)\n",
    "            \n",
    "    for tag in tags:\n",
    "        if tag not in tag_to_index:\n",
    "            tag_to_index[tag] = len(tag_to_index)\n",
    "\n",
    "# add the 'UNK' token\n",
    "word_to_index['<UNK>'] = len(word_to_index)\n",
    "\n",
    "tag_to_index['<UNK>'] = len(tag_to_index)\n",
    "\n",
    "tag_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  1006\n",
      "Number of Tags:  47\n",
      "Number of Intents:  18\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)\n",
    "\n",
    "print(\"Vocabulary Size: \", vocab_size)\n",
    "\n",
    "number_of_tags = len(tag_to_index)\n",
    "\n",
    "print(\"Number of Tags: \", number_of_tags)\n",
    "\n",
    "number_of_intents = len(intent_to_index)\n",
    "\n",
    "print(\"Number of Intents: \", number_of_intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertions\n",
    "i = 0\n",
    "for sentence, tags, intents in training_data:\n",
    "    if len(sentence.split()) != len(tags):\n",
    "        print(f\"Example {i}: Sentence Length: {len(sentence.split())}, Tags Length: {len(tags)}\")\n",
    "        print(\"Example:\", training_data[i])\n",
    "    i +=1\n",
    "\n",
    "for sentence, tags, intents in training_data:\n",
    "    assert len(sentence.split()) == len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'variable declaration': ['O', 'VAR', 'VAL', 'TYPE'], 'function declaration': ['O', 'FUNC', 'PARAM', 'RET_TYPE'], 'class declaration': ['O', 'CLASS_NAME'], 'assignment operation': ['O', 'LHS', 'RHS'], 'conditional operation': ['O', 'LHS', 'RHS', 'CONDITION', 'LOG'], 'iterative operation': ['O', 'LOOP', 'START', 'END', 'LHS', 'RHS', 'CONDITION', 'STEP'], 'array operation': ['O', 'ARRAY', 'OPERATION', 'ELEMENT'], 'bitwise operation': ['O', 'OPERATOR', 'OPERAND'], 'mathematical operation': ['O', 'OPERAND', 'OPERATOR', 'VAR'], 'membership operation': ['O', 'ELEMENT', 'COLLECTION', 'CONDITION'], 'casting': ['O', 'VAR', 'CAST_TYPE'], 'io operation': ['VAR', 'INPUT', 'OUTPUT'], 'assertion': ['O', 'VAR', 'VAL', 'CONDITION'], 'libraries': ['O', 'LIB_NAME'], 'file system': ['O', 'FILE', 'ACTION', 'DIR'], 'ide operation': ['O', 'ACTION', 'TYPE', 'LINE', 'FILE'], 'comment': ['O', 'COMMENT']}\n"
     ]
    }
   ],
   "source": [
    "with open('../ner_dataset/intent_to_tags.json', 'r') as f:\n",
    "    intent_to_tags = json.load(f)\n",
    "\n",
    "print(intent_to_tags)\n",
    "\n",
    "all_tags = list(tag_to_index.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **INTENTS HANDLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# here we want to filter out the tags that are not relevent to the given intent\n",
    "def create_mask(intent, all_tags, intent_to_tags):\n",
    "    intent_tags = intent_to_tags[intent]\n",
    "    final_tags = []\n",
    "\n",
    "    # print(intent_tags)\n",
    "\n",
    "\n",
    "    # create BI tags for the intent\n",
    "    for tag in intent_tags:\n",
    "        # print(tag)\n",
    "        if tag == 'O': \n",
    "            final_tags.append(tag)\n",
    "            continue\n",
    "        \n",
    "        final_tags.append('B-' + tag)\n",
    "        final_tags.append('I-' + tag)\n",
    "\n",
    "    # print(final_tags)\n",
    "        \n",
    "    # mask = [tag in final_tags for tag in all_tags]\n",
    "    # print(mask)\n",
    "    return torch.tensor([tag in final_tags for tag in all_tags], dtype=torch.int32)\n",
    "\n",
    "print(create_mask('comment', all_tags, intent_to_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MODEL DEFINITION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTMCRF(vocab_size, word_embedding_dim=WORD_EMBEDDING_DIM, intent_embedding_dim=INTENT_EMBEDIING_DIM, hidden_dim=HIDDEN_DIM, output_dim=number_of_tags, number_of_intents=number_of_intents)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'variable declaration': ['O', 'VAR', 'VAL', 'TYPE'],\n",
       " 'function declaration': ['O', 'FUNC', 'PARAM', 'RET_TYPE'],\n",
       " 'class declaration': ['O', 'CLASS_NAME'],\n",
       " 'assignment operation': ['O', 'LHS', 'RHS'],\n",
       " 'conditional operation': ['O', 'LHS', 'RHS', 'CONDITION', 'LOG'],\n",
       " 'iterative operation': ['O',\n",
       "  'LOOP',\n",
       "  'START',\n",
       "  'END',\n",
       "  'LHS',\n",
       "  'RHS',\n",
       "  'CONDITION',\n",
       "  'STEP'],\n",
       " 'array operation': ['O', 'ARRAY', 'OPERATION', 'ELEMENT'],\n",
       " 'bitwise operation': ['O', 'OPERATOR', 'OPERAND'],\n",
       " 'mathematical operation': ['O', 'OPERAND', 'OPERATOR', 'VAR'],\n",
       " 'membership operation': ['O', 'ELEMENT', 'COLLECTION', 'CONDITION'],\n",
       " 'casting': ['O', 'VAR', 'CAST_TYPE'],\n",
       " 'io operation': ['VAR', 'INPUT', 'OUTPUT'],\n",
       " 'assertion': ['O', 'VAR', 'VAL', 'CONDITION'],\n",
       " 'libraries': ['O', 'LIB_NAME'],\n",
       " 'file system': ['O', 'FILE', 'ACTION', 'DIR'],\n",
       " 'ide operation': ['O', 'ACTION', 'TYPE', 'LINE', 'FILE'],\n",
       " 'comment': ['O', 'COMMENT']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_to_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'variable declaration': ['O',\n",
       "  'B-VAR',\n",
       "  'I-VAR',\n",
       "  'B-VAL',\n",
       "  'I-VAL',\n",
       "  'B-TYPE',\n",
       "  'I-TYPE'],\n",
       " 'function declaration': ['O',\n",
       "  'B-FUNC',\n",
       "  'I-FUNC',\n",
       "  'B-PARAM',\n",
       "  'I-PARAM',\n",
       "  'B-RET_TYPE',\n",
       "  'I-RET_TYPE'],\n",
       " 'class declaration': ['O', 'B-CLASS_NAME', 'I-CLASS_NAME'],\n",
       " 'assignment operation': ['O', 'B-LHS', 'I-LHS', 'B-RHS', 'I-RHS'],\n",
       " 'conditional operation': ['O',\n",
       "  'B-LHS',\n",
       "  'I-LHS',\n",
       "  'B-RHS',\n",
       "  'I-RHS',\n",
       "  'B-CONDITION',\n",
       "  'I-CONDITION',\n",
       "  'B-LOG',\n",
       "  'I-LOG'],\n",
       " 'iterative operation': ['O',\n",
       "  'B-LOOP',\n",
       "  'I-LOOP',\n",
       "  'B-START',\n",
       "  'I-START',\n",
       "  'B-END',\n",
       "  'I-END',\n",
       "  'B-LHS',\n",
       "  'I-LHS',\n",
       "  'B-RHS',\n",
       "  'I-RHS',\n",
       "  'B-CONDITION',\n",
       "  'I-CONDITION',\n",
       "  'B-STEP',\n",
       "  'I-STEP'],\n",
       " 'array operation': ['O',\n",
       "  'B-ARRAY',\n",
       "  'I-ARRAY',\n",
       "  'B-OPERATION',\n",
       "  'I-OPERATION',\n",
       "  'B-ELEMENT',\n",
       "  'I-ELEMENT'],\n",
       " 'bitwise operation': ['O',\n",
       "  'B-OPERATOR',\n",
       "  'I-OPERATOR',\n",
       "  'B-OPERAND',\n",
       "  'I-OPERAND'],\n",
       " 'mathematical operation': ['O',\n",
       "  'B-OPERAND',\n",
       "  'I-OPERAND',\n",
       "  'B-OPERATOR',\n",
       "  'I-OPERATOR',\n",
       "  'B-VAR',\n",
       "  'I-VAR'],\n",
       " 'membership operation': ['O',\n",
       "  'B-ELEMENT',\n",
       "  'I-ELEMENT',\n",
       "  'B-COLLECTION',\n",
       "  'I-COLLECTION',\n",
       "  'B-CONDITION',\n",
       "  'I-CONDITION'],\n",
       " 'casting': ['O', 'B-VAR', 'I-VAR', 'B-CAST_TYPE', 'I-CAST_TYPE'],\n",
       " 'io operation': ['B-VAR',\n",
       "  'I-VAR',\n",
       "  'B-INPUT',\n",
       "  'I-INPUT',\n",
       "  'B-OUTPUT',\n",
       "  'I-OUTPUT'],\n",
       " 'assertion': ['O',\n",
       "  'B-VAR',\n",
       "  'I-VAR',\n",
       "  'B-VAL',\n",
       "  'I-VAL',\n",
       "  'B-CONDITION',\n",
       "  'I-CONDITION'],\n",
       " 'libraries': ['O', 'B-LIB_NAME', 'I-LIB_NAME'],\n",
       " 'file system': ['O',\n",
       "  'B-FILE',\n",
       "  'I-FILE',\n",
       "  'B-ACTION',\n",
       "  'I-ACTION',\n",
       "  'B-DIR',\n",
       "  'I-DIR'],\n",
       " 'ide operation': ['O',\n",
       "  'B-ACTION',\n",
       "  'I-ACTION',\n",
       "  'B-TYPE',\n",
       "  'I-TYPE',\n",
       "  'B-LINE',\n",
       "  'I-LINE',\n",
       "  'B-FILE',\n",
       "  'I-FILE'],\n",
       " 'comment': ['O', 'B-COMMENT', 'I-COMMENT']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tags = {}\n",
    "for intent in intent_to_tags.keys():\n",
    "    final_tags[intent] = []\n",
    "    for tag in intent_to_tags[intent]:\n",
    "        if tag == 'O': \n",
    "            final_tags[intent].append(tag)\n",
    "            continue\n",
    "        \n",
    "        final_tags[intent].append('B-' + tag)\n",
    "        final_tags[intent].append('I-' + tag)   \n",
    "\n",
    "final_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 4])\n",
      "[[26, 26, 43, 26, 11, 12, 2, 26, 0, 0, 0, 11, 14, 30, 12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\TorchCRF\\__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorCompare.cpp:519.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    }
   ],
   "source": [
    "# Check predictions before training\n",
    "precheck_tag = prepare_sequence(training_data[50][1], tag_to_index)\n",
    "print(precheck_tag)\n",
    "\n",
    "mask = create_mask(training_data[50][2], all_tags, intent_to_tags)\n",
    "\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[50][0].split(), word_to_index)\n",
    "    intent = training_data[50][2]\n",
    "    # precheck_intent = prepare_sequence(intent[0], intent_to_index)\n",
    "    precheck_intent = torch.tensor([intent_to_index[intent]], dtype=torch.long)\n",
    "    print(model(precheck_sent, precheck_intent, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'variable declaration': 0,\n",
       " 'function declaration': 1,\n",
       " 'class declaration': 2,\n",
       " 'assignment operation': 3,\n",
       " 'array operation': 4,\n",
       " 'bitwise operation': 5,\n",
       " 'mathematical operation': 6,\n",
       " 'membership operation': 7,\n",
       " 'casting': 8,\n",
       " 'io operation': 9,\n",
       " 'assertion': 10,\n",
       " 'libraries': 11,\n",
       " 'file system': 12,\n",
       " 'ide operation': 13,\n",
       " 'comment': 14,\n",
       " 'conditional operation': 15,\n",
       " 'iterative operation': 16,\n",
       " '<UNK>': 17}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:32<26:46, 32.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 7.698023501867535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [01:06<26:39, 33.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 3.1732494366306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [01:33<23:48, 30.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 1.9488176893913882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [01:56<21:13, 27.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 1.5023032319956813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [02:23<20:30, 27.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 1.1906722329676835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [02:49<19:39, 26.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 1.0269634893570823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [03:18<19:50, 27.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.9006607410825532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [03:50<20:10, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.8238964517089142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [04:15<18:56, 27.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.725253511187674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [04:38<17:35, 26.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.6488760428593077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [05:03<16:47, 25.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.6031573503866963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [05:30<16:31, 26.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.5465973766370752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [05:58<16:34, 26.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.5325797879010782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [06:29<16:53, 28.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.48552325588533246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [06:55<16:00, 27.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.4678784504156003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [07:19<14:53, 26.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 0.4448672671701716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [07:44<14:19, 26.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.39938758762403465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [08:11<14:02, 26.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.3784531718286975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [08:41<14:06, 27.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Loss: 0.3471995165156222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [09:06<13:23, 26.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.3416163841335253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [09:31<12:39, 26.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 0.3461082796118725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [09:58<12:16, 26.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Loss: 0.31138490391873763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [10:24<11:53, 26.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Loss: 0.2763744345478628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [10:56<12:08, 28.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Loss: 0.2791789013215865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [11:21<11:14, 26.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Loss: 0.2613852823191676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [11:45<10:24, 26.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Loss: 0.2549947466795472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [12:10<09:56, 25.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Loss: 0.24538033803304035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [12:37<09:36, 26.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Loss: 0.2331170163209411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [13:07<09:34, 27.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Loss: 0.22245768404555047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [13:30<08:41, 26.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Loss: 0.2048123287332469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [13:53<07:56, 25.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 0.20675718241724475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [14:17<07:24, 24.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Loss: 0.19596913392516388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [14:42<07:01, 24.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Loss: 0.18883218655641051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [15:10<06:51, 25.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Loss: 0.18639669221023034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [15:39<06:39, 26.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Loss: 0.17502437635399828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [16:01<05:57, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Loss: 0.17587931578186736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [16:25<05:24, 24.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Loss: 0.158732286650559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [16:51<05:01, 25.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Loss: 0.16307031828781654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [17:18<04:43, 25.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Loss: 0.15480661940300602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [17:46<04:24, 26.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Loss: 0.154908333263178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [18:09<03:47, 25.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Loss: 0.14885128810487944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [18:34<03:23, 25.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Loss: 0.13738907342669607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [19:00<02:57, 25.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Loss: 0.14360280793288657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [19:26<02:34, 25.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Loss: 0.13296407326884654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [19:45<01:58, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Loss: 0.12006974231237652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [20:00<01:24, 21.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Loss: 0.1404572401375606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [20:15<00:57, 19.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Loss: 0.12279759856476181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [20:30<00:36, 18.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Loss: 0.11076239531067596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [20:45<00:17, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Loss: 0.1178958441197187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [21:02<00:00, 25.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Loss: 0.11571337338151604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "def train(model, training_data, epochs=10):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        total_loss = 0\n",
    "        for sentence, tags, intent in training_data:\n",
    "            # Step 1. Remember that Pytorch accumulates gradients.\n",
    "            # We need to clear them out before each instance\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Step 2. Get our inputs ready for the network, that is,\n",
    "            # turn them into Tensors of word indices.\n",
    "            intent_mask = create_mask(intent, all_tags, intent_to_tags)\n",
    "            \n",
    "            # print(intent)\n",
    "            # print(intent_to_index[intent])\n",
    "            # intent = prepare_sequence(intents[0], intent_to_index)\n",
    "            # print(intent)\n",
    "            sentence = prepare_sequence(sentence.split(), word_to_index)\n",
    "            target_tags = torch.tensor([tag_to_index[t] for t in tags], dtype=torch.long)\n",
    "            intent = torch.tensor([intent_to_index[intent]], dtype=torch.long)\n",
    "\n",
    "\n",
    "            # Step 3. Run our forward pass.\n",
    "            loss = model.neg_log_likelihood(sentence, target_tags, intent, intent_mask)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch: {epoch}, Loss: {total_loss / len(training_data)}\")\n",
    "\n",
    "train(model, training_data, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 4])\n",
      "[[0, 0, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 4]]\n"
     ]
    }
   ],
   "source": [
    "# Check predictions before training\n",
    "precheck_tag = prepare_sequence(training_data[50][1], tag_to_index)\n",
    "print(precheck_tag)\n",
    "\n",
    "mask = create_mask(training_data[50][2], all_tags, intent_to_tags)\n",
    "\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[50][0].split(), word_to_index)\n",
    "    intent = training_data[50][2]\n",
    "    # precheck_intent = prepare_sequence(intent[0], intent_to_index)\n",
    "    precheck_intent = torch.tensor([intent_to_index[intent]], dtype=torch.long)\n",
    "    print(model(precheck_sent, precheck_intent, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_data):\n",
    "    predictions = [] \n",
    "    with torch.no_grad():\n",
    "        for sentence, _, intent in test_data:\n",
    "            precheck_sent = prepare_sequence(sentence.split(), word_to_index)\n",
    "            # precheck_intent = prepare_sequence(intent, intent_to_index)\n",
    "            precheck_intent = torch.tensor([intent_to_index[intent]], dtype=torch.long)\n",
    "            mask = create_mask(intent, all_tags, intent_to_tags)\n",
    "            predictions.append(model(precheck_sent, precheck_intent, mask)[0])\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Example: 0\n",
      "Actual tags: ['O', 'O', 'O', 'O', 'B-VAR', 'I-VAR', 'O', 'O', 'O', 'B-VAL', 'I-VAL']\n",
      "Predicted tags: ['O', 'O', 'O', 'O', 'B-VAR', 'I-VAR', 'O', 'O', 'O', 'O', 'B-VAL', 'I-VAL']\n",
      "Test Example: 1\n",
      "Actual tags: ['O', 'B-VAR', 'O', 'O', 'B-CAST_TYPE']\n",
      "Predicted tags: ['O', 'B-VAR', 'O', 'O', 'B-CAST_TYPE']\n",
      "Test Example: 2\n",
      "Actual tags: ['O', 'O', 'B-LIB_NAME', 'O']\n",
      "Predicted tags: ['O', 'O', 'B-LIB_NAME', 'O']\n",
      "Test Example: 3\n",
      "Actual tags: ['O', 'O', 'O', 'B-COMMENT', 'I-COMMENT', 'I-COMMENT', 'I-COMMENT', 'I-COMMENT']\n",
      "Predicted tags: ['O', 'I-COMMENT', 'O', 'I-COMMENT', 'I-COMMENT', 'O', 'I-COMMENT', 'I-COMMENT', 'O']\n",
      "Test Example: 4\n",
      "Actual tags: ['O', 'O', 'O', 'O', 'B-CLASS_NAME']\n",
      "Predicted tags: ['O', 'O', 'O', 'O', 'B-CLASS_NAME']\n",
      "Test Example: 5\n",
      "Actual tags: ['O', 'O', 'O', 'O', 'O', 'B-FUNC', 'O', 'O', 'O', 'B-PARAM', 'O', 'B-PARAM']\n",
      "Predicted tags: ['O', 'O', 'O', 'O', 'O', 'B-FUNC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Test Example: 6\n",
      "Actual tags: ['O', 'O', 'O', 'O', 'O', 'B-FUNC', 'O', 'O', 'O', 'B-PARAM', 'O', 'B-PARAM']\n",
      "Predicted tags: ['O', 'O', 'O', 'O', 'O', 'B-FUNC', 'O', 'O', 'O', 'B-PARAM', 'O', 'B-FUNC']\n"
     ]
    }
   ],
   "source": [
    "# Check predictions before training\n",
    "test_example_1 = (\"create a variable called ay khara and set it to yasmine ghanem\", [\"O\", \"O\", \"O\", \"O\", \"B-VAR\", \"I-VAR\", \"O\", \"O\", \"O\", \"B-VAL\", \"I-VAL\"], \"variable declaration\")\n",
    "test_example_2 = (\"cast x to an int\", [\"O\", \"B-VAR\", \"O\", \"O\", \"B-CAST_TYPE\"], \"casting\")\n",
    "test_example_3 = (\"import the pandas library\", [\"O\", \"O\", \"B-LIB_NAME\", \"O\"], \"libraries\")\n",
    "test_example_4 = ('write a new comment multiply the emissions and transitions', ['O', 'O', 'O', 'B-COMMENT', 'I-COMMENT', 'I-COMMENT', 'I-COMMENT', 'I-COMMENT' ], 'comment')\n",
    "test_example_5 = ('define a new class person', ['O', 'O', 'O', 'O', 'B-CLASS_NAME'], 'class declaration')\n",
    "test_example_6 = ('create a new function named add that takes parameters a and b', ['O', 'O', 'O', 'O', 'O', 'B-FUNC', 'O', 'O', 'O', 'B-PARAM', 'O', 'B-PARAM'], 'function declaration')\n",
    "test_example_7 = ('create a new function named add that takes parameters num1 and num2', ['O', 'O', 'O', 'O', 'O', 'B-FUNC', 'O', 'O', 'O', 'B-PARAM', 'O', 'B-PARAM'], 'function declaration')\n",
    "\n",
    "test_data = [test_example_1, test_example_2, test_example_3, test_example_4, test_example_5, test_example_6, test_example_7]\n",
    "\n",
    "predictions = predict(model, test_data)\n",
    "labels = []\n",
    "predicted_tags = []\n",
    "\n",
    "for index, prediction in enumerate(predictions):\n",
    "    print(\"Test Example:\", index)\n",
    "    mapped_tags = [all_tags[tag] for tag in prediction]\n",
    "    predicted_tags.append(mapped_tags)\n",
    "    labels.append(test_data[index][1])\n",
    "    print(\"Actual tags:\", test_data[index][1])\n",
    "    print(\"Predicted tags:\", mapped_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8888888888888888\n",
      "Precision: 0.8888888888888888\n",
      "Recall: 0.8888888888888888\n",
      "Accuracy: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yazmi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluation \n",
    "def evaluate(y_true, y_pred):\n",
    "    # y_true = []\n",
    "    # y_pred = []\n",
    "    # for index, prediction in enumerate(predictions):\n",
    "    #     y_true.extend(test_data[index][1])\n",
    "    #     y_pred.extend([all_tags[tag] for tag in prediction])\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_true_binarized = mlb.fit_transform(y_true)\n",
    "    y_pred_binarized = mlb.transform(y_pred)\n",
    "    \n",
    "    f1 = f1_score(y_true_binarized, y_pred_binarized, average='weighted')\n",
    "    precision = precision_score(y_true_binarized, y_pred_binarized, average='weighted')\n",
    "    recall = recall_score(y_true_binarized, y_pred_binarized, average='weighted')\n",
    "    accuracy = accuracy_score(y_true_binarized, y_pred_binarized)\n",
    "    \n",
    "    return f1, precision, recall, accuracy\n",
    "\n",
    "f1, precision, recall, accuracy = evaluate(labels, predicted_tags)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
