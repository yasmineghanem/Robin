{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to the CSV files\n",
    "train_path = './train.csv'\n",
    "test_path = './test.csv'\n",
    "# lookid_path = './IdLookupTable.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n",
    "# lookid_data = pd.read_csv(lookid_path)\n",
    "\n",
    "# Columns for Y_train\n",
    "y_columns = [\n",
    "    'left_eye_center_x','left_eye_center_y',\n",
    "    'right_eye_center_x','right_eye_center_y',\n",
    "    'nose_tip_x', 'nose_tip_y',\n",
    "    'mouth_left_corner_x', 'mouth_left_corner_y',\n",
    "    'mouth_right_corner_x', 'mouth_right_corner_y',\n",
    "    'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
    "    'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y'\n",
    "]\n",
    "\n",
    "# Select the Image column for X_train\n",
    "X_train = train_data['Image']\n",
    "\n",
    "# Select the specified columns for Y_train\n",
    "Y_train = train_data[y_columns]\n",
    "\n",
    "# Concatenate X_train and Y_train to process all rows\n",
    "combined_data = pd.concat([X_train, Y_train], axis=1)\n",
    "\n",
    "# Mediapipe setup\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Function to detect face landmarks\n",
    "def detect_face_landmarks(image):\n",
    "    results = face_mesh.process(image)\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "        return landmarks\n",
    "    return None\n",
    "\n",
    "# Process all images using Mediapipe\n",
    "for idx, row in combined_data.iterrows():\n",
    "    image = np.fromstring(row['Image'], sep=' ').reshape(96, 96)\n",
    "    image_rgb = cv2.cvtColor(image.astype('uint8'), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    landmarks = detect_face_landmarks(image_rgb)\n",
    "    if landmarks:\n",
    "        # Fill the keypoints using the detected landmarks\n",
    "        row['nose_tip_x'] = landmarks[4].x * 96\n",
    "        row['nose_tip_y'] = landmarks[4].y * 96\n",
    "        row['mouth_left_corner_x'] = landmarks[61].x * 96\n",
    "        row['mouth_left_corner_y'] = landmarks[61].y * 96\n",
    "        row['mouth_right_corner_x'] = landmarks[291].x * 96\n",
    "        row['mouth_right_corner_y'] = landmarks[291].y * 96\n",
    "        row['mouth_center_top_lip_x'] = landmarks[0].x * 96\n",
    "        row['mouth_center_top_lip_y'] = landmarks[0].y * 96\n",
    "        row['mouth_center_bottom_lip_x'] = landmarks[17].x * 96\n",
    "        row['mouth_center_bottom_lip_y'] = landmarks[17].y * 96\n",
    "        row['left_eye_center_x'] = landmarks[263].x * 96\n",
    "        row['left_eye_center_y'] = landmarks[263].y * 96\n",
    "        row['right_eye_center_x'] = landmarks[33].x * 96\n",
    "        row['right_eye_center_y'] = landmarks[33].y * 96\n",
    "\n",
    "        # Update the row in the combined_data DataFrame\n",
    "        combined_data.loc[idx] = row\n",
    "\n",
    "# Drop rows still having any missing values (if any)\n",
    "combined_data = combined_data.dropna()\n",
    "\n",
    "# Split the combined data back into X_train and Y_train\n",
    "X_train = combined_data['Image']\n",
    "Y_train = combined_data[y_columns]\n",
    "\n",
    "# Convert X_train to numpy array and reshape\n",
    "X_train = np.array([np.fromstring(image, sep=' ').reshape(96, 96, 1) for image in X_train])\n",
    "X_train = X_train.astype('float32') / 255.0  # Normalize pixel values\n",
    "\n",
    "# Convert Y_train to numpy array\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(len(Y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(96, 96, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(30, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(14))\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "#default learning rate is 0.0001. Loss curve isnt converging so lets try with higher learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae', 'accuracy'])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, Y_train, epochs=300, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Read the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Resize the image to 96x96\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    # Normalize the image\n",
    "    image = image.astype('float32') / 255.0\n",
    "    # Reshape the image to match the input shape of the model\n",
    "    image = np.reshape(image, (1, 96, 96, 1))\n",
    "    return image\n",
    "\n",
    "# Define a function to plot the image with keypoints\n",
    "def plot_image_with_keypoints(image_path, keypoints):\n",
    "    # Read the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Resize the image to 96x96\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    keypoints = keypoints.reshape(-1, 2)\n",
    "    for (x, y) in keypoints:\n",
    "        plt.plot(x, y, 'ro')\n",
    "    plt.show()\n",
    "\n",
    "# Preprocess the image\n",
    "image_path = 'Untitled.png'\n",
    "preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "# Predict the keypoints\n",
    "predicted_points = model.predict(preprocessed_image)\n",
    "\n",
    "# Plot the image with the predicted keypoints\n",
    "plot_image_with_keypoints(image_path, predicted_points[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_name = '/model'\n",
    "# Save the model in TensorFlow SavedModel format\n",
    "model.save(mode_name)\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Compress the saved model directory\n",
    "shutil.make_archive(mode_name, 'zip', mode_name)\n",
    "\n",
    "# Download the zipped model\n",
    "files.download(mode_name+'.zip')\n",
    "\n",
    "\n",
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted model to a .tflite file\n",
    "tflite_model_path = 'model.tflite'\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "files.download(tflite_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Paths to the CSV files\n",
    "train_path = './train.csv'\n",
    "test_path = './test.csv'\n",
    "# lookid_path = './IdLookupTable.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n",
    "# lookid_data = pd.read_csv(lookid_path)\n",
    "\n",
    "# Columns for Y_train\n",
    "y_columns = [\n",
    "    'left_eye_center_x','left_eye_center_y',\n",
    "    'right_eye_center_x','right_eye_center_y',\n",
    "    'nose_tip_x', 'nose_tip_y',\n",
    "    'mouth_left_corner_x', 'mouth_left_corner_y',\n",
    "    'mouth_right_corner_x', 'mouth_right_corner_y',\n",
    "    'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
    "    'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y'\n",
    "]\n",
    "\n",
    "# Select the Image column for X_train\n",
    "X_train = train_data['Image']\n",
    "\n",
    "# Select the specified columns for Y_train\n",
    "Y_train = train_data[y_columns]\n",
    "\n",
    "# Concatenate X_train and Y_train to process all rows\n",
    "combined_data = pd.concat([X_train, Y_train], axis=1)\n",
    "\n",
    "# Mediapipe setup\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Function to detect face landmarks\n",
    "def detect_face_landmarks(image):\n",
    "    results = face_mesh.process(image)\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "        return landmarks\n",
    "    return None\n",
    "\n",
    "# Process all images using Mediapipe\n",
    "for idx, row in combined_data.iterrows():\n",
    "    image = np.fromstring(row['Image'], sep=' ').reshape(96, 96)\n",
    "    image_rgb = cv2.cvtColor(image.astype('uint8'), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    landmarks = detect_face_landmarks(image_rgb)\n",
    "    if landmarks:\n",
    "        # Fill the keypoints using the detected landmarks\n",
    "        row['nose_tip_x'] = landmarks[4].x * 96\n",
    "        row['nose_tip_y'] = landmarks[4].y * 96\n",
    "        row['mouth_left_corner_x'] = landmarks[61].x * 96\n",
    "        row['mouth_left_corner_y'] = landmarks[61].y * 96\n",
    "        row['mouth_right_corner_x'] = landmarks[291].x * 96\n",
    "        row['mouth_right_corner_y'] = landmarks[291].y * 96\n",
    "        row['mouth_center_top_lip_x'] = landmarks[0].x * 96\n",
    "        row['mouth_center_top_lip_y'] = landmarks[0].y * 96\n",
    "        row['mouth_center_bottom_lip_x'] = landmarks[17].x * 96\n",
    "        row['mouth_center_bottom_lip_y'] = landmarks[17].y * 96\n",
    "        row['left_eye_center_x'] = landmarks[263].x * 96\n",
    "        row['left_eye_center_y'] = landmarks[263].y * 96\n",
    "        row['right_eye_center_x'] = landmarks[33].x * 96\n",
    "        row['right_eye_center_y'] = landmarks[33].y * 96\n",
    "\n",
    "        # Update the row in the combined_data DataFrame\n",
    "        combined_data.loc[idx] = row\n",
    "\n",
    "# Drop rows still having any missing values (if any)\n",
    "combined_data = combined_data.dropna()\n",
    "\n",
    "# Split the combined data back into X_train and Y_train\n",
    "X_train = combined_data['Image']\n",
    "Y_train = combined_data[y_columns]\n",
    "\n",
    "# Convert X_train to numpy array and reshape\n",
    "X_train = np.array([np.fromstring(image, sep=' ').reshape(96, 96, 1) for image in X_train])\n",
    "X_train = X_train.astype('float32') / 255.0  # Normalize pixel values\n",
    "\n",
    "# Convert Y_train to numpy array\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(len(Y_train))\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(96, 96, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(30, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(14))\n",
    "\n",
    "\n",
    "#default learning rate is 0.0001. Loss curve isnt converging so lets try with higher learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae', 'accuracy'])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, Y_train, epochs=300, batch_size=32, validation_split=0.2)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Read the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Resize the image to 96x96\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    # Normalize the image\n",
    "    image = image.astype('float32') / 255.0\n",
    "    # Reshape the image to match the input shape of the model\n",
    "    image = np.reshape(image, (1, 96, 96, 1))\n",
    "    return image\n",
    "\n",
    "# Define a function to plot the image with keypoints\n",
    "def plot_image_with_keypoints(image_path, keypoints):\n",
    "    # Read the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Resize the image to 96x96\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    keypoints = keypoints.reshape(-1, 2)\n",
    "    for (x, y) in keypoints:\n",
    "        plt.plot(x, y, 'ro')\n",
    "    plt.show()\n",
    "\n",
    "# Preprocess the image\n",
    "image_path = 'Untitled.png'\n",
    "preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "# Predict the keypoints\n",
    "predicted_points = model.predict(preprocessed_image)\n",
    "\n",
    "# Plot the image with the predicted keypoints\n",
    "plot_image_with_keypoints(image_path, predicted_points[0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
